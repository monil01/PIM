@inproceedings{monil2022mapredict,
  title={MAPredict: Static Analysis Driven Memory Access Prediction Framework for Modern CPUs},
  author={Monil, Mohammad Alaul Haque and Lee, Seyong and Vetter, Jeffrey S and Malony, Allen D},
  booktitle={International Conference on High Performance Computing},
  pages={233--255},
  year={2022},
  organization={Springer}
}

@misc{ecpapp,
  title = {ECP Proxy Application},
  howpublished = {\url{https://proxyapps.exascaleproject.org/app/}},
  note = {Accessed: 2022-08-30}
}

@techreport{karlin2012lulesh,
  title={Lulesh programming model and performance ports overview},
  author={Karlin, I.},
  year={2012},
  institution={Lawrence Livermore National Lab.(LLNL), CA, United States)}
}

@Misc{01,
  author           = {Ataberk Olgun and Juan Gómez Luna and Konstantinos Kanellopoulos and Behzad Salami and Hasan Hassan and Oğuz Ergin and Onur Mutlu},
  date             = {2021},
  title            = {PiDRAM: A Holistic End-to-end FPGA-based Framework for Processing-in-DRAM},
  eprint           = {2111.00082},
  eprintclass      = {cs.AR},
  eprinttype       = {arXiv},
  abstract         = {Processing-using-memory (PuM) techniques leverage the analog operation of memory cells to perform computation. Several recent works have demonstrated PuM techniques in off-the-shelf DRAM devices. Since DRAM is the dominant memory technology as main memory in current computing systems, these PuM techniques represent an opportunity for alleviating the data movement bottleneck at very low cost. However, system integration of PuM techniques imposes non-trivial challenges that are yet to be solved. Design space exploration of potential solutions to the PuM integration challenges requires appropriate tools to develop necessary hardware and software components. Unfortunately, current specialized DRAM-testing platforms, or system simulators do not provide the flexibility and/or the holistic system view that is necessary to deal with PuM integration challenges.
We design and develop PiDRAM, the first flexible end-to-end framework that
enables system integration studies and evaluation of real PuM techniques.
PiDRAM provides software and hardware components to rapidly integrate PuM
techniques across the whole system software and hardware stack (e.g., necessary
modifications in the operating system, memory controller). We implement PiDRAM
on an FPGA-based platform along with an open-source RISC-V system. Using
PiDRAM, we implement and evaluate two state-of-the-art PuM techniques: in-DRAM
(i) copy and initialization, (ii) true random number generation. Our results
show that the in-memory copy and initialization techniques can improve the
performance of bulk copy operations by 12.6x and bulk initialization operations
by 14.6x on a real system. Implementing the true random number generator
requires only 190 lines of Verilog and 74 lines of C code using PiDRAM's
software and hardware components.},
  file             = {:Olgun2021.pdf:PDF},
  groups           = {PIM, Sawtooth, Architecture Reading Group},
  modificationdate = {2021-12-01T17:14:02},
}

@InProceedings{Karandikar2021,
  author           = {Karandikar, Sagar and Leary, Chris and Kennelly, Chris and Zhao, Jerry and Parimi, Dinesh and Nikolic, Borivoje and Asanovic, Krste and Ranganathan, Parthasarathy},
  booktitle        = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
  date             = {2021},
  title            = {A Hardware Accelerator for Protocol Buffers},
  doi              = {10.1145/3466752.3480051},
  isbn             = {9781450385572},
  location         = {Virtual Event, Greece},
  pages            = {462–478},
  publisher        = {Association for Computing Machinery},
  series           = {MICRO '21},
  url              = {https://doi.org/10.1145/3466752.3480051},
  abstract         = {Serialization frameworks are a fundamental component of scale-out systems, but introduce
significant compute overheads. However, they are amenable to acceleration with specialized
hardware. To understand the trade-offs involved in architecting such an accelerator,
we present the first in-depth study of serialization framework usage at scale by profiling
Protocol Buffers (“protobuf”) usage across Google’s datacenter fleet. We use this
data to build HyperProtoBench, an open-source benchmark representative of key serialization-framework
user services at scale. In doing so, we identify key insights that challenge prevailing
assumptions about serialization framework usage. We use these insights to develop
a novel hardware accelerator for protobufs, implemented in RTL and integrated into
a RISC-V SoC. Applications can easily harness the accelerator, as it integrates with
a modified version of the open-source protobuf library and is wire-compatible with
standard protobufs. We have fully open-sourced our RTL, which, to the best of our
knowledge, is the only such implementation currently available to the community. We
also present a first-of-its-kind, end-to-end evaluation of our entire RTL-based system
running hyperscale-derived benchmarks and microbenchmarks. We boot Linux on the system
using FireSim to run these benchmarks and implement the design in a commercial 22nm
FinFET process to obtain area and frequency metrics. We demonstrate an average 6.2
\texttimes{} to 11.2 \texttimes{} performance improvement vs. our baseline RISC-V SoC with BOOM OoO cores
and despite the RISC-V SoC’s weaker uncore/supporting components, an average 3.8 \texttimes{}
improvement vs. a Xeon-based server.},
  address          = {New York, NY, USA},
  file             = {:Karandikar2021.pdf:PDF},
  keywords         = {hardware-acceleration, profiling, hyperscale systems, deserialization, warehouse-scale computing, serialization},
  modificationdate = {2021-12-01T17:28:54},
  numpages         = {17},
}

@Misc{02,
  author           = {Saugata Ghose and Kevin Hsieh and Amirali Boroumand and Rachata Ausavarungnirun and Onur Mutlu},
  date             = {2018},
  title            = {Enabling the Adoption of Processing-in-Memory: Challenges, Mechanisms, Future Research Directions},
  eprint           = {1802.00320},
  eprintclass      = {cs.AR},
  eprinttype       = {arXiv},
  file             = {:ghose2018enabling.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:54},
}

@Misc{03,
  author           = {Baohua Sun and Daniel Liu and Leo Yu and Jay Li and Helen Liu and Wenhan Zhang and Terry Torng},
  date             = {2018},
  title            = {MRAM Co-designed Processing-in-Memory CNN Accelerator for Mobile and IoT Applications},
  eprint           = {1811.12179},
  eprintclass      = {eess.SP},
  eprinttype       = {arXiv},
  file             = {:sun2018mram.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:54},
}

@Misc{04,
  author           = {Sourjya Roy and Mustafa Ali and Anand Raghunathan},
  date             = {2021},
  title            = {PIM-DRAM: Accelerating Machine Learning Workloads using Processing in Commodity DRAM},
  eprint           = {2105.03736},
  eprintclass      = {cs.LG},
  eprinttype       = {arXiv},
  file             = {:roy2021pimdram.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:54},
}

@Misc{05,
  author           = {Juan Gómez-Luna and Izzat El Hajj and Ivan Fernandez and Christina Giannoula and Geraldo F. Oliveira and Onur Mutlu},
  date             = {2021},
  title            = {Benchmarking a New Paradigm: An Experimental Analysis of a Real Processing-in-Memory Architecture},
  eprint           = {2105.03814},
  eprintclass      = {cs.AR},
  eprinttype       = {arXiv},
  file             = {:gómezluna2021benchmarking.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2022-02-22T17:26:24},
}

@InProceedings{06,
  author           = {Imani, Mohsen and Gupta, Saransh and Kim, Yeseong and Zhou, Minxuan and Rosing, Tajana},
  booktitle        = {Proceedings of the 2019 on Great Lakes Symposium on VLSI},
  date             = {2019},
  title            = {DigitalPIM: Digital-Based Processing In-Memory for Big Data Acceleration},
  doi              = {10.1145/3299874.3319483},
  isbn             = {9781450362528},
  location         = {Tysons Corner, VA, USA},
  pages            = {429–434},
  publisher        = {Association for Computing Machinery},
  series           = {GLSVLSI '19},
  url              = {https://doi.org/10.1145/3299874.3319483},
  abstract         = {In this work, we design, DigitalPIM, a Digital-based Processing In-Memory platform capable of accelerating fundamental big data algorithms in real time with orders of magnitude more energy efficient operation. Unlike the existing near-data processing approach such as HMC 2.0, which utilizes additional low-power processing cores next to memory blocks, the proposed platform implements the entire algorithm directly in memory blocks without using extra processing units. In our platform, each memory block supports the essential operations including: bitwise operation, addition/multiplication, and search operation internally in memory without reading any values out of the block. This significantly mitigates the processing costs of the new architecture, while providing high scalability and parallelism for performing the extensive computations. We exploit these essential operations to accelerate popular big data applications entirely in memory such as machine learning algorithms, query processing, and graph processing. Our evaluations show that for all tested applications, the performance can be accelerated significantly by eliminating the memory access bottleneck},
  address          = {New York, NY, USA},
  file             = {:10.1145_3299874.3319483.pdf:PDF},
  groups           = {PIM},
  keywords         = {non-volatile memories, processing in memory, energy efficiency, big data acceleration},
  modificationdate = {2021-12-01T17:28:54},
  numpages         = {6},
}

@InProceedings{07,
  author           = {Kang, Hongbo and Gibbons, Phillip B. and Blelloch, Guy E. and Dhulipala, Laxman and Gu, Yan and McGuffey, Charles},
  booktitle        = {Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and Architectures},
  date             = {2021},
  title            = {The Processing-in-Memory Model},
  doi              = {10.1145/3409964.3461816},
  isbn             = {9781450380706},
  location         = {Virtual Event, USA},
  pages            = {295–306},
  publisher        = {Association for Computing Machinery},
  series           = {SPAA '21},
  url              = {https://doi.org/10.1145/3409964.3461816},
  abstract         = {As computational resources become more efficient and data sizes grow, data movement is fast becoming the dominant cost in computing. Processing-in-Memory is emerging as a key technique for reducing costly data movement, by enabling computation to be executed on compute resources embedded in the memory modules themselves.  This paper presents the Processing-in-Memory (PIM) model, for the design and analysis of parallel algorithms on systems providing processing-in-memory modules. The PIM model focuses on keys aspects of such systems, while abstracting the rest. Namely, the model combines (i) a CPU-side consisting of parallel cores with fast access to a small shared memory of size M words (as in traditional parallel computing), (ii) a PIM-side consisting of P PIM modules, each with a core and a local memory of size Θ(n/P) words for an input of size n (as in traditional distributed computing), and (iii) a network between the two sides. The model combines standard parallel complexity metrics for both shared memory (work and depth) and distributed memory (local work, communication time) computing. A key algorithmic challenge is to achieve load balance among the PIM modules in both their communication and their local work, while minimizing the communication time. We demonstrate how to overcome this challenge for an ordered search structure, presenting a parallel PIM-skiplist data structure that efficiently supports a wide range of batch-parallel queries and updates.},
  address          = {New York, NY, USA},
  file             = {:10.1145_3409964.3461816.pdf:PDF},
  groups           = {PIM},
  keywords         = {processing-in-memory, skip list, batch-parallel data structures, models of parallel computation},
  modificationdate = {2021-12-01T17:28:54},
  numpages         = {12},
}

@InBook{08,
  author           = {Jiao, Bo and Zhu, Haozhe and Zhang, Jinshan and Wang, Shunli and Kang, Xiaoyang and Zhang, Lihua and Wang, Mingyu and Chen, Chixiao},
  booktitle        = {Proceedings of the 2021 on Great Lakes Symposium on VLSI},
  date             = {2021},
  title            = {Computing Utilization Enhancement for Chiplet-Based Homogeneous Processing-in-Memory Deep Learning Processors},
  isbn             = {9781450383936},
  location         = {New York, NY, USA},
  pages            = {241–246},
  publisher        = {Association for Computing Machinery},
  url              = {https://doi.org/10.1145/3453688.3461499},
  abstract         = {This paper presents a design strategy of chiplet-based processing-in-memory systems for deep neural network applications. Monolithic silicon chips are area and power limited, failing to catch the recent rapid growth of deep learning algorithms. The paper first demonstrates a straightforward layer-wise method that partitions the workload of a monolithic accelerator to a multi-chiplet pipeline. A quantitative analysis shows that the straightforward separation degrades the overall utilization of computing resources due to the reduced on-chiplet memory size, thus introducing a higher memory wall. A tile interleaving strategy is proposed to overcome such degradation. This strategy can segment one layer to different chiplets which maximizes the computing utilization. To facilitate the strategy, the modification of the chiplet system hardware is also discussed. To validate the proposed strategy, a nine-chiplet processing-in-memory system is evaluated with a custom-designed object detection network. Each chiplet can achieve a peak performance of 204.8GOPS at a 100-MHz rate. The peak performance of the overall system is 1.711TOPS, where no off-chip memory access is needed. By the tile interleaving strategy, the utilization is improved from 53.9 to 92.8},
  file             = {:10.1145_3453688.3461499.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:30:38},
  numpages         = {6},
}

@Article{09,
  author           = {Park, Naebeom and Ryu, Sungju and Kung, Jaeha and Kim, Jae-Joon},
  date             = {2021-06},
  journaltitle     = {ACM Trans. Des. Autom. Electron. Syst.},
  title            = {High-Throughput Near-Memory Processing on CNNs with 3D HBM-like Memory},
  doi              = {10.1145/3460971},
  issn             = {1084-4309},
  number           = {6},
  url              = {https://doi.org/10.1145/3460971},
  volume           = {26},
  abstract         = {This article discusses the high-performance near-memory neural network (NN) accelerator architecture utilizing the logic die in three-dimensional (3D) High Bandwidth Memory– (HBM) like memory. As most of the previously reported 3D memory-based near-memory NN accelerator designs used the Hybrid Memory Cube (HMC) memory, we first focus on identifying the key differences between HBM and HMC in terms of near-memory NN accelerator design. One of the major differences between the two 3D memories is that HBM has the centralized through-silicon-via (TSV) channels while HMC has distributed TSV channels for separate vaults. Based on the observation, we introduce the Round-Robin Data Fetching and Groupwise Broadcast schemes to exploit the centralized TSV channels for improvement of the data feeding rate for the processing elements. Using synthesized designs in a 28-nm CMOS technology, performance and energy consumption of the proposed architectures with various dataflow models are evaluated. Experimental results show that the proposed schemes reduce the runtime by 16.4–39.3\% on average and the energy consumption by 2.1–5.1\% on average compared to conventional data fetching schemes.},
  articleno        = {48},
  file             = {:10.1145_3460971.pdf:PDF},
  groups           = {PIM},
  issue_date       = {November 2021},
  keywords         = {HBM, Neural network accelerator},
  location         = {New York, NY, USA},
  modificationdate = {2021-12-01T17:28:54},
  numpages         = {20},
  publisher        = {Association for Computing Machinery},
}

@Article{10,
  author           = {Long, Yun and Kim, Daehyun and Lee, Edward and Saha, Priyabrata and Mudassar, Burhan Ahmad and She, Xueyuan and Khan, Asif Islam and Mukhopadhyay, Saibal},
  date             = {2019},
  journaltitle     = {IEEE Journal on Exploratory Solid-State Computational Devices and Circuits},
  title            = {A Ferroelectric FET-Based Processing-in-Memory Architecture for DNN Acceleration},
  doi              = {10.1109/JXCDC.2019.2923745},
  number           = {2},
  pages            = {113-122},
  volume           = {5},
  abstract         = {This paper presents a ferroelectric FET (FeFET)-based processing-in-memory (PIM) architecture to accelerate the inference of deep neural networks (DNNs). We propose a digital in-memory vector-matrix multiplication (VMM) engine design utilizing the FeFET crossbar to enable bit-parallel computation and eliminate analog-to-digital conversion in prior mixed-signal PIM designs. A dedicated hierarchical network-on-chip (H-NoC) is developed for input broadcasting and on-the-fly partial results processing, reducing the data transmission volume and latency. Simulations in 28-nm CMOS technology show 115×and 6.3×higher computing efficiency (GOPs/W) over desktop GPU (NvidiaGTX1080Ti) and resistive random access memory (ReRAM)-based design, respectively.},
  comment          = {This work uses a FeFET-based PIM architecture to accelerate DNN inference. FeFET is used as the basic memory cell and the Vector-Vector Multiplication (VVM) is ADC free. A dedicated Hierarchical NoC (H-NoC) is developed to realize fast and parallel data communication with broadcast features and accumulation enabled in the routers.},
  file             = {:8740886.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2022-01-19T12:31:51},
  qualityassured   = {qualityAssured},
  readstatus       = {read},
}

@Misc{11,
  author           = {Youngeun Kwon and Minsoo Rhu},
  date             = {2019},
  title            = {Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep Learning},
  eprint           = {1902.06468},
  eprintclass      = {cs.DC},
  eprinttype       = {arXiv},
  abstract         = {As the models and the datasets to train deep learning (DL) models scale, system architects are faced with new challenges, one of which is the memory capacity bottleneck, where the limited physical memory inside the accelerator device constrains the algorithm that can be studied. We propose a memory-centric deep learning system that can transparently expand the memory capacity available to the accelerators while also providing fast inter-device communication for parallel training. Our proposal aggregates a pool of memory modules locally within the deviceside interconnect, which are decoupled from the host interface and function as a vehicle for transparent memory capacity expansion. Compared to conventional systems, our proposal achieves an average 2.8× speedup on eight DL applications and increases the system-wide memory capacity to tens of TBs.},
  comment          = {This paper proposes a memory-centric deep learning system which greatly expands the amount of memory provided to the accelerators by designing a system which incorporates memory modules within the device side interconnect.},
  file             = {:kwon2019memory.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2022-01-25T22:06:57},
  qualityassured   = {qualityAssured},
}

@InProceedings{12,
  author           = {Lee, Sukhan and Kang, Shin-haeng and Lee, Jaehoon and Kim, Hyeonsu and Lee, Eojin and Seo, Seungwoo and Yoon, Hosang and Lee, Seungwon and Lim, Kyounghwan and Shin, Hyunsung and Kim, Jinhyun and Seongil, O and Iyer, Anand and Wang, David and Sohn, Kyomin and Kim, Nam Sung},
  booktitle        = {2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)},
  date             = {2021},
  title            = {Hardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology : Industrial Product},
  doi              = {10.1109/ISCA52012.2021.00013},
  pages            = {43-56},
  file             = {:9499894.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:54},
}

@Misc{13,
  author           = {Orian Leitersdorf and Ronny Ronen and Shahar Kvatinsky},
  date             = {2021},
  title            = {MultPIM: Fast Stateful Multiplication for Processing-in-Memory},
  eprint           = {2108.13378},
  eprintclass      = {cs.AR},
  eprinttype       = {arXiv},
  file             = {:leitersdorf2021multpim.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{14,
  author           = {Gupta, Saransh and Imani, Mohsen and Kaur, Harveen and Rosing, Tajana Simunic},
  date             = {2019},
  journaltitle     = {IEEE Transactions on Computers},
  title            = {NNPIM: A Processing In-Memory Architecture for Neural Network Acceleration},
  doi              = {10.1109/TC.2019.2903055},
  number           = {9},
  pages            = {1325-1337},
  volume           = {68},
  abstract         = {Neural networks (NNs) have shown great ability to process emerging applications such as speech recognition, language recognition, image classification, video segmentation, and gaming. It is therefore important to make NNs efficient. Although attempts have been made to improve NNs’ computation cost, the data movement between memory and processing cores is the main bottleneck for NNs’ energy consumption and execution time. This makes the implementation of NNs significantly slower on traditional CPU/GPU cores. In this paper, we propose a novel processing in-memory architecture, called NNPIM, that significantly accelerates neural network’s inference phase inside the memory. First, we design a crossbar memory architecture that supports fast addition, multiplication, and search operations inside the memory. Second, we introduce simple optimization techniques which significantly improves NNs’ performance and reduces the overall energy consumption. We also map all NN functionalities using parallel in-memory components. To further improve the efficiency, our design supports weight sharing to reduce the number of computations in memory and consecutively speedup NNPIM computation. We compare the efficiency of our proposed NNPIM with GPU and the state-of-the-art PIM architectures. Our evaluation shows that our design can achieve 131.5 higher energy efficiency and is 48.2 faster as compared to NVIDIA GTX 1,080 GPU architecture. Compared to state-of-the-art neural network accelerators, NNPIM can achieve on an average 3.6 higher energy efficiency and is 4.6 faster, while providing the same classification accuracy.},
  file             = {:8658117.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2022-02-02T22:04:12},
}

@InProceedings{15,
  author           = {Peng, Xiaochen and Liu, Rui and Yu, Shimeng},
  booktitle        = {2019 IEEE International Symposium on Circuits and Systems (ISCAS)},
  date             = {2019},
  title            = {Optimizing Weight Mapping and Data Flow for Convolutional Neural Networks on RRAM Based Processing-In-Memory Architecture},
  doi              = {10.1109/ISCAS.2019.8702715},
  pages            = {1-5},
  file             = {:8702715.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{16,
  author           = {Jeon, Won and Lee, Jiwon and Kang, Dongseok and Kal, Hongju and Ro, Won Woo},
  date             = {2021},
  journaltitle     = {IEEE Access},
  title            = {PIMCaffe: Functional Evaluation of a Machine Learning Framework for In-Memory Neural Processing Unit},
  doi              = {10.1109/ACCESS.2021.3094043},
  pages            = {96629-96640},
  volume           = {9},
  file             = {:9469808.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{17,
  author           = {Ghose, S. and Boroumand, A. and Kim, J. S. and Gómez-Luna, J. and Mutlu, O.},
  date             = {2019},
  journaltitle     = {IBM Journal of Research and Development},
  title            = {Processing-in-memory: A workload-driven perspective},
  doi              = {10.1147/JRD.2019.2934048},
  number           = {6},
  pages            = {3:1-3:19},
  volume           = {63},
  file             = {:8792187.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Misc{18,
  author           = {Arman Roohi and Shaahin Angizi and Deliang Fan and Ronald F DeMara},
  date             = {2019},
  title            = {Processing-In-Memory Acceleration of Convolutional Neural Networks for Energy-Efficiency, and Power-Intermittency Resilience},
  eprint           = {1904.07864},
  eprintclass      = {cs.LG},
  eprinttype       = {arXiv},
  file             = {:roohi2019processinginmemory.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@InProceedings{19,
  author           = {Liu, Jiawen and Zhao, Hengyu and Ogleari, Matheus A. and Li, Dong and Zhao, Jishen},
  booktitle        = {2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  date             = {2018},
  title            = {Processing-in-Memory for Energy-Efficient Neural Network Training: A Heterogeneous Approach},
  doi              = {10.1109/MICRO.2018.00059},
  pages            = {655-668},
  file             = {:8574576.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{20,
  author           = {Long, Yun and Na, Taesik and Mukhopadhyay, Saibal},
  date             = {2018},
  journaltitle     = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  title            = {ReRAM-Based Processing-in-Memory Architecture for Recurrent Neural Network Acceleration},
  doi              = {10.1109/TVLSI.2018.2819190},
  number           = {12},
  pages            = {2781-2794},
  volume           = {26},
  file             = {:8402126.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{21,
  author           = {Kim, Seongguk and Kim, Subin and Cho, Kyungjun and Shin, Taein and Park, Hyunwook and Lho, Daehwan and Park, Shinyoung and Son, Kyungjune and Park, Gapyeol and Jeong, Seungtaek and Kim, Youngwoo and Kim, Joungho},
  date             = {2021},
  journaltitle     = {IEEE Transactions on Components, Packaging and Manufacturing Technology},
  title            = {Signal Integrity and Computing Performance Analysis of a Processing-In-Memory of High Bandwidth Memory (PIM-HBM) Scheme},
  doi              = {10.1109/TCPMT.2021.3117071},
  pages            = {1-1},
  file             = {:9555642.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@Article{22,
  author           = {Wang, Yi and Chen, Weixuan and Yang, Jing and Li, Tao},
  date             = {2018},
  journaltitle     = {IEEE Transactions on Parallel and Distributed Systems},
  title            = {Towards Memory-Efficient Allocation of CNNs on Processing-in-Memory Architecture},
  doi              = {10.1109/TPDS.2018.2791440},
  number           = {6},
  pages            = {1428-1441},
  volume           = {29},
  file             = {:8252752.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:55},
}

@InProceedings{23,
  author           = {Ke, Liu and Gupta, Udit and Cho, Benjamin Youngjae and Brooks, David and Chandra, Vikas and Diril, Utku and Firoozshahian, Amin and Hazelwood, Kim and Jia, Bill and Lee, Hsien-Hsin S. and Li, Meng and Maher, Bert and Mudigere, Dheevatsa and Naumov, Maxim and Schatz, Martin and Smelyanskiy, Mikhail and Wang, Xiaodong and Reagen, Brandon and Wu, Carole-Jean and Hempstead, Mark and Zhang, Xuan},
  booktitle        = {2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  date             = {2020},
  title            = {RecNMP: Accelerating Personalized Recommendation with Near-Memory Processing},
  doi              = {10.1109/ISCA45697.2020.00070},
  pages            = {790-803},
  file             = {:9138955.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@Misc{24,
  author           = {Zhe Zhou and Cong Li and Xuechao Wei and Guangyu Sun},
  date             = {2021},
  title            = {GCNear: A Hybrid Architecture for Efficient GCN Training with Near-Memory Processing},
  eprint           = {2111.00680},
  eprintclass      = {cs.LG},
  eprinttype       = {arXiv},
  file             = {:zhou2021gcnear.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@InProceedings{25,
  author           = {Joel Nider and Craig Mustard and Andrada Zoltan and John Ramsden and Larry Liu and Jacob Grossbard and Mohammad Dashti and Romaric Jodin and Alexandre Ghiti and Jordi Chauzi and Alexandra Fedorova},
  booktitle        = {2021 {USENIX} Annual Technical Conference ({USENIX} {ATC} 21)},
  date             = {2021-07},
  title            = {A Case Study of Processing-in-Memory in off-the-Shelf Systems},
  isbn             = {978-1-939133-23-6},
  pages            = {117--130},
  publisher        = {{USENIX} Association},
  url              = {https://www.usenix.org/conference/atc21/presentation/nider},
  file             = {:273853.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@InProceedings{26,
  author           = {Gu, Peng and Xie, Xinfeng and Ding, Yufei and Chen, Guoyang and Zhang, Weifeng and Niu, Dimin and Xie, Yuan},
  booktitle        = {2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  date             = {2020},
  title            = {iPIM: Programmable In-Memory Image Processing Accelerator Using Near-Bank Architecture},
  doi              = {10.1109/ISCA45697.2020.00071},
  pages            = {804-817},
  file             = {:9138985.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@Article{27,
  author           = {S.Hosseini, Maryam and Ebrahimi, Masoumeh and Yaghini, Pooria and Bagherzadeh, Nader},
  date             = {2021},
  journaltitle     = {IEEE Transactions on Emerging Topics in Computing},
  title            = {Near Volatile and Non-Volatile Memory Processing in 3D Systems},
  doi              = {10.1109/TETC.2021.3115495},
  pages            = {1-1},
  file             = {:9556138.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@InProceedings{28,
  author           = {Kim, Jin Hyun and Kang, Shin-haeng and Lee, Sukhan and Kim, Hyeonsu and Song, Woongjae and Ro, Yuhwan and Lee, Seungwon and Wang, David and Shin, Hyunsung and Phuah, Bengseng and Choi, Jihyun and So, Jinin and Cho, YeonGon and Song, JoonHo and Choi, Jangseok and Cho, Jeonghyeon and Sohn, Kyomin and Sohn, Youngsoo and Park, Kwangil and Kim, Nam Sung},
  booktitle        = {2021 IEEE Hot Chips 33 Symposium (HCS)},
  date             = {2021},
  title            = {Aquabolt-XL: Samsung HBM2-PIM with in-memory processing for ML accelerators and beyond},
  doi              = {10.1109/HCS52781.2021.9567191},
  pages            = {1-26},
  file             = {:9567191.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:28:56},
}

@Article{29,
  author           = {Lu, Anni and Peng, Xiaochen and Luo, Yandong and Huang, Shanshi and Yu, Shimeng},
  date             = {2021-06},
  journaltitle     = {ACM Trans. Des. Autom. Electron. Syst.},
  title            = {A Runtime Reconfigurable Design of Compute-in-Memory–Based Hardware Accelerator for Deep Learning Inference},
  doi              = {10.1145/3460436},
  issn             = {1084-4309},
  number           = {6},
  url              = {https://doi.org/10.1145/3460436},
  volume           = {26},
  abstract         = {Compute-in-memory (CIM) is an attractive solution to address the “memory wall” challenges for the extensive computation in deep learning hardware accelerators. For custom ASIC design, a specific chip instance is restricted to a specific network during runtime. However, the development cycle of the hardware is normally far behind the emergence of new algorithms. Although some of the reported CIM-based architectures can adapt to different deep neural network (DNN) models, few details about the dataflow or control were disclosed to enable such an assumption. Instruction set architecture (ISA) could support high flexibility, but its complexity would be an obstacle to efficiency. In this article, a runtime reconfigurable design methodology of CIM-based accelerators is proposed to support a class of convolutional neural networks running on one prefabricated chip instance with ASIC-like efficiency. First, several design aspects are investigated: (1) the reconfigurable weight mapping method; (2) the input side of data transmission, mainly about the weight reloading; and (3) the output side of data processing, mainly about the reconfigurable accumulation. Then, a system-level performance benchmark is performed for the inference of different DNN models, such as VGG-8 on a CIFAR-10 dataset and AlexNet GoogLeNet, ResNet-18, and DenseNet-121 on an ImageNet dataset to measure the trade-offs between runtime reconfigurability, chip area, memory utilization, throughput, and energy efficiency.},
  articleno        = {45},
  file             = {:10.1145_3460436.pdf:PDF},
  groups           = {PIM},
  issue_date       = {November 2021},
  keywords         = {reconfigurable architecture, compute-in-memory, Convolutional neural network, hardware accelerator},
  location         = {New York, NY, USA},
  modificationdate = {2021-12-01T17:24:52},
  numpages         = {18},
  publisher        = {Association for Computing Machinery},
}

@InProceedings{30,
  author           = {Ahn, Junwhan and Yoo, Sungjoo and Mutlu, Onur and Choi, Kiyoung},
  booktitle        = {2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)},
  date             = {2015},
  title            = {PIM-enabled instructions: A low-overhead, locality-aware processing-in-memory architecture},
  doi              = {10.1145/2749469.2750385},
  pages            = {336-348},
  file             = {:7284077.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:24:21},
}

@InBook{31,
  author           = {Lin, Che-Chia and Lee, Chao-Lin and Lee, Jenq-Kuen and Wang, Howard and Hung, Ming-Yu},
  booktitle        = {50th International Conference on Parallel Processing Workshop},
  date             = {2021},
  title            = {Accelerate Binarized Neural Networks with Processing-in-Memory Enabled by RISC-V Custom Instructions},
  isbn             = {9781450384414},
  location         = {New York, NY, USA},
  publisher        = {Association for Computing Machinery},
  url              = {https://doi.org/10.1145/3458744.3473351},
  abstract         = {As the speed of processing units grows rapidly, the bottleneck of system’s performance is usually the speed of memory, and the situation is the so-called ”Memory Wall”. There are emerging technologies trying to take down the ”Memory Wall”, and one of them is Processing-in-Memory (PIM). Processing-in-Memory means that the data are processed just inside the memory itself. It does not need to take time to travel between CPU and Memory. Moreover, for very little modifications to memory devices, the memory can do primitive bit-wise operations at the memory side. Binarized Neural Network (BNN), which replaces the convolution’s multiplication and addition operations with bit-wise AND and population count operations, is therefore suited for utilizing PIM to gain performance. This work architects PIM AND, NOT, and population count operations and enables PIM operations working under RISC-V custom instruction encodings. Besides, we also utilize TVM’s support of BNN for application sources. In addition, we offer a new design for BNN’s convolution in which a better memory layout is considered. With our design, the results of the speedup range from 3.7x to 57.3x comparing with CPU-based system for the execution time of end-to-end BNN model inferences.},
  articleno        = {15},
  file             = {:10.1145_3458744.3473351.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:24:53},
  numpages         = {8},
}

@InProceedings{32,
  author           = {Boroumand, Amirali and Ghose, Saugata and Patel, Minesh and Hassan, Hasan and Lucia, Brandon and Ausavarungnirun, Rachata and Hsieh, Kevin and Hajinazar, Nastaran and Malladi, Krishna T. and Zheng, Hongzhong and Mutlu, Onur},
  booktitle        = {Proceedings of the 46th International Symposium on Computer Architecture},
  date             = {2019},
  title            = {CoNDA: Efficient Cache Coherence Support for near-Data Accelerators},
  doi              = {10.1145/3307650.3322266},
  isbn             = {9781450366694},
  location         = {Phoenix, Arizona},
  pages            = {629–642},
  publisher        = {Association for Computing Machinery},
  series           = {ISCA '19},
  url              = {https://doi.org/10.1145/3307650.3322266},
  abstract         = {Specialized on-chip accelerators are widely used to improve the energy efficiency of computing systems. Recent advances in memory technology have enabled near-data accelerators (NDAs), which reside off-chip close to main memory and can yield further benefits than on-chip accelerators. However, enforcing coherence with the rest of the system, which is already a major challenge for accelerators, becomes more difficult for NDAs. This is because (1) the cost of communication between NDAs and CPUs is high, and (2) NDA applications generate a lot of off-chip data movement. As a result, as we show in this work, existing coherence mechanisms eliminate most of the benefits of NDAs. We extensively analyze these mechanisms, and observe that (1) the majority of off-chip coherence traffic is unnecessary, and (2) much of the off-chip traffic can be eliminated if a coherence mechanism has insight into the memory accesses performed by the NDA.Based on our observations, we propose CoNDA, a coherence mechanism that lets an NDA optimistically execute an NDA kernel, under the assumption that the NDA has all necessary coherence permissions. This optimistic execution allows CoNDA to gather information on the memory accesses performed by the NDA and by the rest of the system. CoNDA exploits this information to avoid performing unnecessary coherence requests, and thus, significantly reduces data movement for coherence.We evaluate CoNDA using state-of-the-art graph processing and hybrid in-memory database workloads. Averaged across all of our workloads operating on modest data set sizes, CoNDA improves performance by 19.6\% over the highest-performance prior coherence mechanism (66.0\%/51.7\% over a CPU-only/NDA-only system) and reduces memory system energy consumption by 18.0\% over the most energy-efficient prior coherence mechanism (43.7\% over CPU-only). CoNDA comes within 10.4\% and 4.4\% of the performance and energy of an ideal mechanism with no cost for coherence. The benefits of CoNDA increase with large data sets, as CoNDA improves performance over the highest-performance prior coherence mechanism by 38.3\% (8.4x/7.7x over CPU-only/NDA-only), and comes within 10.2\% of an ideal no-cost coherence mechanism.},
  address          = {New York, NY, USA},
  file             = {:10.1145_3307650.3322266.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:24:03},
  numpages         = {14},
}

@InProceedings{33,
  author           = {Huang, Yu and Zheng, Long and Yao, Pengcheng and Zhao, Jieshan and Liao, Xiaofei and Jin, Hai and Xue, Jingling},
  booktitle        = {2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  date             = {2020},
  title            = {A Heterogeneous PIM Hardware-Software Co-Design for Energy-Efficient Graph Processing},
  doi              = {10.1109/IPDPS47924.2020.00076},
  pages            = {684-695},
  file             = {:9139839.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:24:03},
}

@InProceedings{34,
  author           = {Pattnaik, Ashutosh and Tang, Xulong and Jog, Adwait and Kayiran, Onur and Mishra, Asit K. and Kandemir, Mahmut T. and Mutlu, Onur and Das, Chita R.},
  booktitle        = {2016 International Conference on Parallel Architecture and Compilation Techniques (PACT)},
  date             = {2016},
  title            = {Scheduling techniques for GPU architectures with processing-in-memory capabilities},
  doi              = {10.1145/2967938.2967940},
  pages            = {31-44},
  file             = {:7756764.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-01T17:23:46},
}

@Article{35,
  author           = {Zhang, Jialiang and Zha, Yue and Beckwith, Nicholas and Liu, Bangya and Li, Jing},
  date             = {2020-09},
  journaltitle     = {ACM Trans. Reconfigurable Technol. Syst.},
  title            = {MEG: A RISCV-Based System Emulation Infrastructure for Near-Data Processing Using FPGAs and High-Bandwidth Memory},
  doi              = {10.1145/3409114},
  issn             = {1936-7406},
  number           = {4},
  url              = {https://doi.org/10.1145/3409114},
  volume           = {13},
  abstract         = {Emerging three-dimensional (3D) memory technologies, such as the Hybrid Memory Cube (HMC) and High Bandwidth Memory (HBM), provide high-bandwidth and massive memory-level parallelism. With the growing heterogeneity and complexity of computer systems (CPU cores and accelerators, etc.), efficiently integrating emerging memories into existing systems poses new challenges and requires detailed evaluation in a realistic computing environment. In this article, we propose MEG, an open source, configurable, cycle-exact, and RISC-V-based full-system emulation infrastructure using FPGA and HBM. MEG provides a highly modular hardware design and includes a bootable Linux image for a realistic software flow, so that users can perform cross-layer software-hardware co-optimization in a full-system environment. To improve the observability and debuggability of the system, MEG also provides a flexible performance monitoring scheme to guide the performance optimization. The proposed MEG infrastructure can potentially benefit broad communities across computer architecture, system software, and application software. Leveraging MEG, we present two cross-layer system optimizations as illustrative cases to demonstrate the usability of MEG. In the first case study, we present a reconfigurable memory controller to improve the address mapping of standard memory controller. This reconfigurable memory controller along with its OS support allows us to optimize the address mapping scheme to fully exploit the massive parallelism provided by the emerging three-dimensional (3D) memories. In the second case study, we present a lightweight IOMMU design to tackle the unique challenges brought by 3D memory in providing virtual memory support for near-memory accelerators. We provide a prototype implementation of MEG on a Xilinx VU37P FPGA and demonstrate its capability, fidelity, and flexibility on real-world benchmark applications. We hope MEG fills a gap in the space of publicly available FPGA-based full-system emulation infrastructures, specifically targeting memory systems, and inspires further collaborative software/hardware innovations.},
  articleno        = {19},
  file             = {:10.1145_3409114.pdf:PDF},
  groups           = {PIM},
  issue_date       = {October 2020},
  keywords         = {3d-stacking memory, near-memory acceleration, high bandwidth memory, address mapping scheme, RISC-V core, Full-system emulation, FPGAs},
  location         = {New York, NY, USA},
  modificationdate = {2021-12-01T17:23:46},
  numpages         = {24},
  publisher        = {Association for Computing Machinery},
}

@InProceedings{10.1145/3466752.3480064,
  author           = {Xie, Zhiyao and Xu, Xiaoqing and Walker, Matt and Knebel, Joshua and Palaniswamy, Kumaraguru and Hebert, Nicolas and Hu, Jiang and Yang, Huanrui and Chen, Yiran and Das, Shidhartha},
  booktitle        = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
  date             = {2021},
  title            = {APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors},
  doi              = {10.1145/3466752.3480064},
  isbn             = {9781450385572},
  location         = {Virtual Event, Greece},
  pages            = {1–14},
  publisher        = {Association for Computing Machinery},
  series           = {MICRO '21},
  abstract         = {Accurate power modeling is crucial for energy-efficient CPU design and runtime management.
An ideal power modeling framework needs to be accurate yet fast, achieve high temporal
resolution (ideally cycle-accurate) yet with low runtime computational overheads,
and easily extensible to diverse designs through automation. Simultaneously satisfying
such conflicting objectives is challenging and largely unattained despite significant
prior research. In this paper, we propose APOLLO, an automated per-cycle power modeling
framework that serves as the basis for both a design-time power estimator and a low-overhead
runtime on-chip power meter (OPM). APOLLO uses the minimax concave penalty (MCP)-based
feature selection algorithm to automatically select less than 0.05\% of RTL signals
as power proxies. The power estimation achieves R2 &gt; 0.95 on Arm Neoverse N1&nbsp;[3] and
R2 &gt; 0.94 on Arm Cortex-A77&nbsp;[2] microprocessors, respectively. When integrated with
an emulator-assisted flow, APOLLO finishes per-cycle power estimation on millions-of-cycles
benchmark in minutes for million-gate industrial CPU designs. Furthermore, the power
model is synthesized and integrated into the microprocessor implementation as a runtime
OPM. APOLLO’s accuracy further improves when coarse-grained temporal resolution is
preferred. To our best knowledge, this is the first runtime OPM that simultaneously
achieves per-cycle temporal resolution and area/power overhead without compromising
accuracy, which is validated on high-performance, out-of-order industrial CPU designs.},
  address          = {New York, NY, USA},
  creationdate     = {2021-11-12T14:20:46},
  file             = {:10.1145_3466752.3480064.pdf:PDF},
  groups           = {Architecture Reading Group},
  keywords         = {on-chip power meter, Power modeling and estimation, voltage droop, commercial microprocessors, machine learning},
  modificationdate = {2021-12-01T17:14:02},
  numpages         = {14},
}

@InProceedings{10.1145/331532.331589,
  author           = {Hall, Mary and Kogge, Peter and Koller, Jeff and Diniz, Pedro and Chame, Jacqueline and Draper, Jeff and LaCoss, Jeff and Granacki, John and Brockman, Jay and Srivastava, Apoorv and Athas, William and Freeh, Vincent and Shin, Jaewook and Park, Joonseok},
  booktitle        = {Proceedings of the 1999 ACM/IEEE Conference on Supercomputing},
  date             = {1999},
  title            = {Mapping Irregular Applications to DIVA, a PIM-Based Data-Intensive Architecture},
  doi              = {10.1145/331532.331589},
  isbn             = {1581130910},
  location         = {Portland, Oregon, USA},
  pages            = {57–es},
  publisher        = {Association for Computing Machinery},
  series           = {SC '99},
  url              = {https://doi.org/10.1145/331532.331589},
  address          = {New York, NY, USA},
  file             = {:10.1145_331532.331589.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-03T09:55:32},
}

@Article{37,
  author           = {Chang, Liang and Li, Chenglong and Zhang, Zhaomin and Xiao, Jianbiao and Liu, Qingsong and Zhu, Zhen and Li, Weihang and Zhu, Zixuan and Yang, Siqi and Zhou, Jun},
  date             = {2021},
  journaltitle     = {Science China Information Sciences},
  title            = {Energy-efficient computing-in-memory architecture for AI processor: device, circuit, architecture perspective},
  doi              = {10.1007/s11432-021-3234-0},
  issn             = {1869-1919},
  number           = {6},
  pages            = {160403},
  url              = {https://doi.org/10.1007/s11432-021-3234-0},
  volume           = {64},
  abstract         = {An artificial intelligence (AI) processor is a promising solution for energy-efficient data processing, including health monitoring and image/voice recognition. However, data movements between compute part and memory induce memory wall and power wall challenges to the conventional computing architecture. Recently, the memory-centric architecture has been revised to solve the data movement issue, where the memory is equipped with the compute-capable memory technique, namely, computing-in-memory (CIM). In this paper, we analyze the requirement of AI algorithms on the data movement and low power requirement of AI processors. In addition, we introduce the story of CIM and implementation methodologies of CIM architecture. Furthermore, we present several novel solutions beyond traditional analog-digital mixed static random-access memory (SRAM)-based CIM architecture. Finally, recent CIM tape-out studies are listed and discussed.},
  file             = {:default.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-03T09:57:04},
  refid            = {Chang2021},
}

@Article{38,
  author           = {Drumond, Mario and Daglis, Alexandros and Mirzadeh, Nooshin and Ustiugov, Dmitrii and Picorel, Javier and Falsafi, Babak and Grot, Boris and Pnevmatikatos, Dionisios},
  date             = {2018-08},
  journaltitle     = {SIGOPS Oper. Syst. Rev.},
  title            = {Algorithm/Architecture Co-Design for Near-Memory Processing},
  doi              = {10.1145/3273982.3273992},
  issn             = {0163-5980},
  number           = {1},
  pages            = {109–122},
  url              = {https://doi.org/10.1145/3273982.3273992},
  volume           = {52},
  abstract         = {With mainstream technologies to couple logic tightly with memory on the horizon, near-memory processing has re-emerged as a promising approach to improving performance and energy for data-centric computing. DRAM, however, is primarily designed for density and low cost, with a rigid internal organization that favors coarse-grain streaming rather than byte-level random access. This paper makes the case that treating DRAM as a block-oriented streaming device yields significant efficiency and performance benefits, which motivate for algorithm/architecture co-design to favor streaming access patterns, even at the price of a higher order algorithmic complexity. We present the Mondrian Data Engine that drastically improves the runtime and energy efficiency of basic in-memory analytic operators, despite doing more work as compared to traditional CPU-optimized algorithms, which heavily rely on random accesses and deep cache hierarchies},
  file             = {:10.1145_3273982.3273992.pdf:PDF},
  groups           = {PIM},
  issue_date       = {July 2018},
  location         = {New York, NY, USA},
  modificationdate = {2021-12-03T09:55:32},
  numpages         = {14},
  publisher        = {Association for Computing Machinery},
}

@Article{10.1145/2686875,
  author           = {Morad, Amir and Yavits, Leonid and Ginosar, Ran},
  date             = {2015-01},
  journaltitle     = {ACM Trans. Archit. Code Optim.},
  title            = {GP-SIMD Processing-in-Memory},
  doi              = {10.1145/2686875},
  issn             = {1544-3566},
  number           = {4},
  url              = {https://doi.org/10.1145/2686875},
  volume           = {11},
  abstract         = {GP-SIMD, a novel hybrid general-purpose SIMD computer architecture, resolves the issue of data synchronization by in-memory computing through combining data storage and massively parallel processing. GP-SIMD employs a two-dimensional access memory with modified SRAM storage cells and a bit-serial processing unit per each memory row. An analytic performance model of the GP-SIMD architecture is presented, comparing it to associative processor and to conventional SIMD architectures. Cycle-accurate simulation of four workloads supports the analytical comparison. Assuming a moderate die area, GP-SIMD architecture outperforms both the associative processor and conventional SIMD coprocessor architectures by almost an order of magnitude while consuming less power.},
  articleno        = {53},
  file             = {:10.1145_2686875.pdf:PDF},
  groups           = {PIM},
  issue_date       = {January 2015},
  keywords         = {Multicore, processing in memory, SIMD, associative processor, PIM},
  location         = {New York, NY, USA},
  modificationdate = {2021-12-03T09:55:32},
  numpages         = {26},
  publisher        = {Association for Computing Machinery},
}

@Article{40,
  author           = {Lee, Won Jun and Kim, Chang Hyun and Paik, Yoonah and Park, Jongsun and Park, Il and Kim, Seon Wook},
  date             = {2019},
  journaltitle     = {IEEE Access},
  title            = {Design of Processing-“Inside”-Memory Optimized for DRAM Behaviors},
  doi              = {10.1109/ACCESS.2019.2924240},
  pages            = {82633-82648},
  volume           = {7},
  file             = {:8743357.pdf:PDF},
  groups           = {PIM},
  modificationdate = {2021-12-03T09:55:32},
}




@ARTICLE{Simone, 
author={S. Gerardin and A. Paccagnella}, 
journal={IEEE Transactions on Nuclear Science}, 
title={Present and Future Non-Volatile Memories for Space}, 
year={2010}, 
}


@article{mbptascript,
author = {Abella, Jaume and Padilla, Maria and Castillo, Joan Del and Cazorla, Francisco J.},
title = {Measurement-Based Worst-Case Execution Time Estimation Using the Coefficient of Variation},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
year = {2017},
} 

@article{WCETsurvey,
 author = {Wilhelm, Reinhard and Engblom, Jakob and Ermedahl, Andreas and Holsti, Niklas and Thesing, Stephan and Whalley, David and Bernat, Guillem and Ferdinand, Christian and Heckmann, Reinhold and Mitra, Tulika and Mueller, Frank and Puaut, Isabelle and Puschner, Peter and Staschulat, Jan and Stenstr\"{o}m, Per},
 title = {The Worst-case Execution-time Problem\&Mdash;Overview of Methods and Survey of Tools},
 journal = {ACM Trans. Embed. Comput. Syst.},
 issue_date = {April 2008},

} 



@INPROCEEDINGS{MB_high, 
author={B. Bishop and T. P. Kelliher and M. J. Irwin}, 
booktitle={1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461)}, 
title={A detailed analysis of MediaBench}, 
year={1999}, 

}


@inproceedings{kazimemsys16,
 author = {Asifuzzaman, Kazi and Pavlovic, Milan and Radulovic, Milan and Zaragoza, David and Kwon, Ohseong and Ryoo, Kyung-Chang and Radojkovi\'{c}, Petar},
 title = {{Performance Impact of a Slower Main Memory: A Case Study of STT-MRAM in HPC}},
 booktitle = {Proceedings of the Second International Symposium on Memory Systems},
 series = {MEMSYS},
 year = {2016},

} 

@inproceedings{mediabench,
 author = {Lee, Chunho and Potkonjak, Miodrag and Mangione-Smith, William H.},
 title = {MediaBench: A Tool for Evaluating and Synthesizing Multimedia and Communicatons Systems},
 booktitle = {Proceedings of the 30th Annual ACM/IEEE International Symposium on Microarchitecture},
 series = {MICRO 30},
 year = {1997},

} 


@INPROCEEDINGS{dramerror, 
author={Y. Kim and R. Daly and J. Kim and C. Fallin and J. H. Lee and D. Lee and C. Wilkerson and K. Lai and O. Mutlu}, 
booktitle={41st ACM/IEEE International Symposium on Computer Architecture (ISCA)}, 
title={Flipping bits in memory without accessing them: An experimental study of DRAM disturbance errors}, 
year={2014}, 
}



@inproceedings{senni,
 author = {Senni, Sophiane and Delobelle, Thibaud and Coi, Odilia and Peneau, Pierre-Yves and Torres, Lionel and Gamatie, Abdoulaye and Benoit, Pascal and Sassatelli, Gilles},
 title = {Embedded Systems to High Performance Computing Using STT-MRAM},
 booktitle = {Proceedings of the Conference on Design, Automation \& Test in Europe},2017

} 

@article{brucedramsim,
 author = {Wang, David and Ganesh, Brinda and Tuaycharoen, Nuengwong and Baynes, Kathleen and Jaleel, Aamer and Jacob, Bruce},
 title = {{DRAMsim: A Memory System Simulator}},
 journal = {SIGARCH Comput. Archit. News},
 volume = {33},
 number = {4},
 year = {2005},
 publisher = {ACM}
} 

@INPROCEEDINGS{changl3, 
author={{M. T. Chang and P. Rosenfeld and S. L. Lu and B. Jacob}}, 
booktitle={{IEEE 19th International Symposium on High Performance Computer Architecture}}, 
title={{Technology comparison for large last-level caches (L3Cs): Low-leakage SRAM, low write-energy STT-RAM, and refresh-optimized eDRAM}}, 
year={2013}, 
}

@ARTICLE{nvsim, 
author={X. Dong and C. Xu and Y. Xie and N. P. Jouppi}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={{NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory}},
volume={31}, 
number={7}, 
pages={994-1007},  
year={2012}, 
}

@INPROCEEDINGS{jiang, 
author={Lei Jiang and Wujie Wen and D. Wang and L. Duan}, 
booktitle={21st Asia and South Pacific Design Automation Conference (ASP-DAC)}, 
title={{Improving read performance of STT-MRAM based main memories through Smash Read and Flexible Read}}, 
year={2016}, 
}


@inproceedings{wang,
 author = {Wang, Jue and Dong, Xiangyu and Xie, Yuan},
 title = {{Enabling High-performance LPDDRx-compatible MRAM}},
 series = {ISLPED},
 year={2014}
} 


@misc{EverspinDDR,
    author = {{Everspin Technologies, Inc.}},
    title={{Everspin displays both the 1Gb DDR4 Perpendicular ST-MRAM device and a 1GByte DDR3 Memory Module (DIMM) at Stand A3-545}},
    howpublished = "https://www.everspin.com/news/everspin-previews-upcoming-products-electronica",
   year = {2016}  

}

@ARTICLE{eembc, 
author={J. A. Poovey and T. M. Conte and M. Levy and S. Gal-On}, 
journal={IEEE Micro}, 
title={{A Benchmark Characterization of the EEMBC Benchmark Suite}}, 
year={2009}, 
}

@ARTICLE{dramsim2, 
author={P. Rosenfeld and E. Cooper-Balis and B. Jacob}, 
journal={IEEE Computer Architecture Letters}, 
title={{DRAMSim2: A Cycle Accurate Memory System Simulator}}, 
year={2011}, 
}

@misc{Everspinspace,
    author = {{Everspin Technologies, Inc.}},
    title={{Case Study:  SpriteSat (Rising) Satellite}},
    howpublished = "https://www.everspin.com/aerospace",
   year = {2018}  

}


@inproceedings{Ikeda,
 author = {S. Ikeda and K. Miura and H. Yamamoto and K. Mizunuma and H. D. Gan and	M. Endo and S. Kanai and J. Hayakawa and F. Matsukura and H. Ohno},
 title = {{A perpendicular-anisotropy CoFeB-MgO magnetic tunnel junction}},
 booktitle = {{Nature Materials}},
 volume = {9},
  issue = {9},
  pages = {721--724},
  year = {2010},
 
}

@INPROCEEDINGS{newtoshiba4gb, 
author={K. Rho and K. Tsuchida and D. Kim and Y. Shirai and J. Bae and T. Inaba and H. Noro and H. Moon and S. Chung and K. Sunouchi and J. Park and K. Park and A. Yamamoto and S. Chung and H. Kim and H. Oyamatsu and J. Oh}, 
booktitle={2017 IEEE International Solid-State Circuits Conference (ISSCC)}, 
title={{23.5 A 4Gb LPDDR2 STT-MRAM with compact 9F2 1T1MTJ cell and hierarchical bitline architecture}}, 
year={2017},}



@ARTICLE{Janusz, 
author={J. J. Nowak and R. P. Robertazzi and J. Z. Sun and G. Hu and J. H. Park and J. Lee and A. J. Annunziata and G. P. Lauer and R. Kothandaraman and E. J. O'Sullivan and P. L. Trouilloud and Y. Kim and D. C. Worledge}, 
journal={IEEE Magnetics Letters}, 
title={Dependence of Voltage and Size on Write Error Rates in Spin-Transfer Torque Magnetic Random-Access Memory},
volume={7}, 
pages={1-4},  
year={2016}, 
}


@MANUAL{micronddr2,
  title = {{Automotive DDR2 SDRAM}},
  author = {{Micron Technology, Inc.}},
  year = 2011,
}

@inproceedings{jalle2014,
 author = {Jalle, Javier and Kosmidis, Leonidas and Abella, Jaume and Qui\~{n}ones, Eduardo and Cazorla, Francisco J.},
 title = {Bus Designs for Time-probabilistic Multicore Processors},
 booktitle = {Proceedings of the Conference on Design, Automation \& Test in Europe},
 series = {DATE '14},
 year = {2014},
 isbn = {978-3-9815370-2-4},
 location = {Dresden, Germany},
 url = {http://dl.acm.org/citation.cfm?id=2616606.2616668},

} 


@ARTICLE{sttradhard, 
author={D. Chabi and W. Zhao and J. O. Klein and C. Chappert}, 
journal={IEEE Transactions on Nuclear Science}, 
title={Design and Analysis of Radiation Hardened Sensing Circuits for Spin Transfer Torque Magnetic Memory and Logic}, 
year={2014}, 
doi={10.1109/TNS.2014.2370735}, 
}



@inproceedings{kazimemsys17,
 author = {Asifuzzaman, Kazi and Verdejo, Rommel S\'{a}nchez and Radojkovi\'{c}, Petar},
 title = {Enabling a Reliable STT-MRAM Main Memory Simulation},
 booktitle = {Proceedings of the International Symposium on Memory Systems},
 series = {MEMSYS '17},
 year = {2017},
 isbn = {978-1-4503-5335-9},
 location = {Alexandria, Virginia},
 pages = {283--292},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3132402.3132416},
} 


@misc{everspincar,
    author = {{Everspin Technologies, Inc.}},
    title={{Automotive}},
    howpublished = "https://www.everspin.com/automotive,
    year = {2018},
}

@misc{everspinsite,
    author = {{Everspin Technologies, Inc.}},
    title={{STT-MRAM Products}},
    howpublished = "https://www.everspin.com/stt-mram-products",
    year = {2018},
}


@inproceedings{WEN2005SEUS,
 author = {I. Wenzel and R. Kirner and B. Rieder and P. Puschner},
 title = {Measurement-Based Worst-Case Execution Time Analysis},
 booktitle = {{SEUS} Workshop},
 year = {2005},
} 

@InProceedings{WEN2008ISOLA,
  author =       {I. Wenzel and R. Kirner and B. Rieder and P. Puschner},
  title =        {Measurement-Based Timing Analysis},
  booktitle =    {{ISOLA}},
  year =         {2008},
}

@ARTICLE{Slayman, 
author={C. W. Slayman}, 
journal={IEEE Transactions on Device and Materials Reliability}, 
title={Cache and memory error detection, correction, and reduction techniques for terrestrial servers and workstations}, 
year={2005}, 
volume={5}, 
number={3}, 
pages={397-404}, 
keywords={DRAM chips;SRAM chips;cache storage;error correction codes;error detection codes;failure analysis;fault tolerance;network servers;radiation effects;workstations;DRAM memory;SRAM cache;array interleaving;cache scrubbing;cosmic ray errors;data integrity targets;error correction code;error detection code;fault tolerance;reduction techniques;reliability;soft error rate;terrestrial servers;terrestrial workstations;Blades;Error correction;Error correction codes;File servers;Neutrons;Power system reliability;Random access memory;SRAM chips;Switches;Workstations;Cosmic-ray upset;error correction code (ECC);memory fault tolerance;soft-error rate (SER)}, 
doi={10.1109/TDMR.2005.856487}, 
ISSN={1530-4388}, 
month={Sept},}

@INPROCEEDINGS{MarcDATE, 
author={M. Riera and R. Canal and J. Abella and A. Gonzalez}, 
booktitle={2016 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={A detailed methodology to compute Soft Error Rates in advanced technologies}, 
year={2016}, 
volume={}, 
number={}, 
pages={217-222}, 
keywords={software fault tolerance;FinFET technology;SER;SOI technology;soft error rates;system reliability;Computational modeling;Hardware;Integrated circuit modeling;Logic gates;Neutrons;Reliability;Transistors}, 
doi={}, 
ISSN={}, 
month={March},}

@INPROCEEDINGS{JalleNGMP,
	author={J. Jalle, J. Abella, L. Fossati, M. Zulianello, F. J. Cazorla},
	title={Validating a Timing Simulator for the NGMP Multicore Processor},
	booktitle={2016 DASIA},
	isbn={789292213015}
}

@Book{EVT,
author = {S. {Kotz et al.}},
title = {Extreme value distributions: theory and applications},
publisher = {World Scientific},
year = {2000},
isbn = {1860942245, 9781860942242},
pages = {185}
}

@INPROCEEDINGS{EVTECRTS, 
author={L. Cucu-Grosjean and L. Santinelli and M. Houston and C. Lo and T. Vardanega and L. Kosmidis and J. Abella and E. Mezzetti and E. Quiñones and F. J. Cazorla}, 
booktitle={2012 24th Euromicro Conference on Real-Time Systems}, 
title={Measurement-Based Probabilistic Timing Analysis for Multi-path Programs}, 
year={2012}, 
volume={}, 
number={}, 
pages={91-101}, 
keywords={knowledge based systems;multiprocessing programs;safety-critical software;detail knowledge;extreme value theory;hardware components;measurement-based probabilistic timing analysis;multipath programs;software components;static timing analysis;Computational modeling;Computer architecture;Distribution functions;Hardware;Probabilistic logic;Random variables;Timing;probabilistic real-time systems;timing analysis}, 
doi={10.1109/ECRTS.2012.31}, 
ISSN={1068-3070}, 
month={July},}

@article{bernat4,
         author={Bernat, G. and Newby, M.},
         title={Probabilistic {WCET} analysis, an approach using copulas},
         journal={Journal of Embedded Computing},
         year={2006}
}

@inproceedings{diaz02,
author={D\'iaz, J.L and Garcia, D.F. and Kim,K. and Lee, C.G. and Bello, L.L. and L\'opez J.M.
 and Mirabella, O.},
title={Stochastic Analysis of Periodic Real-Time Systems},
booktitle={the 23rd IEEE Real-Time Systems Symposium (RTSS02)},
year={2002},
 }

@InProceedings{hansen09,
  author =      {J. {Hansen et al.}},
  title =       {Statistical-Based {WCET} Estimation and Validation},
  booktitle =   {WCET Analysis workshop},
  year =        {2009}
}


@article{MBPTAcompliant,
title = "Fitting processor architectures for measurement-based probabilistic timing analysis",
journal = "Microprocessors and Microsystems",
volume = "47",
pages = "287 - 302",
year = "2016",
issn = "0141-9331",
doi = "https://doi.org/10.1016/j.micpro.2016.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0141933116300977",
author = "Leonidas Kosmidis and Eduardo Quiñones and Jaume Abella and Tullio Vardanega and Carles Hernandez and Andrea Gianarro and Ian Broster and Francisco J. Cazorla",
keywords = "Worst-case execution time, Processor architecture, Cache memories, Probabilistic analysis, Time randomization"
}

@InProceedings{EVTWCET,
  author =	{Francisco J. Cazorla and Tullio Vardanega and Eduardo Qui{\~n}ones and Jaume Abella},
  title =	{{Upper-bounding Program Execution Time with Extreme Value Theory}},
  booktitle =	{13th International Workshop on Worst-Case Execution Time Analysis},
  pages =	{64--76},
  series =	{OpenAccess Series in Informatics (OASIcs)},
  ISBN =	{978-3-939897-54-5},
  ISSN =	{2190-6807},
  year =	{2013},
  volume =	{30},
  editor =	{Claire Maiza},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2013/4123},
  URN =		{urn:nbn:de:0030-drops-41232},
  doi =		{10.4230/OASIcs.WCET.2013.64},
  annote =	{Keywords: WCET, Extreme Value Theory, Probabilistic, Deterministic}
}

@INPROCEEDINGS{WCETSIES, 
author={J. Abella and C. Hernandez and E. Quiñones and F. J. Cazorla and P. R. Conmy and M. Azkarate-askasua and J. Perez and E. Mezzetti and T. Vardanega}, 
booktitle={10th IEEE International Symposium on Industrial Embedded Systems (SIES)}, 
title={WCET analysis methods: Pitfalls and challenges on their trustworthiness}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-10}, 
keywords={probability;safety-critical software;trusted computing;WCET analysis methods;WCET estimates;measurement-based methods;probabilistic methods;program execution time;static methods;system timing behaviour;time-critical systems;trustworthiness;trustworthy upper-bounds;user ability;worst-case execution time;Documentation;Hardware;Multicore processing;Safety;Software;Timing}, 
doi={10.1109/SIES.2015.7185039}, 
ISSN={2150-3109}, 
month={June},}

@inproceedings{RandomModulo,
 author = {Hernandez, Carles and Abella, Jaume and Gianarro, Andrea and Andersson, Jan and Cazorla, Francisco J.},
 title = {Random Modulo: A New Processor Cache Design for Real-time Critical Systems},
 booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
 series = {DAC '16},
 year = {2016},
 isbn = {978-1-4503-4236-0},
 location = {Austin, Texas},
 pages = {29:1--29:6},
 articleno = {29},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2897937.2898076},
 doi = {10.1145/2897937.2898076},
 acmid = {2898076},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@ARTICLE{IEEETCrandplacement, 
author={L. Kosmidis and J. Abella and E. Quiñones and F. J. Cazorla}, 
journal={IEEE Transactions on Computers}, 
title={Efficient Cache Designs for Probabilistically Analysable Real-Time Systems}, 
year={2014}, 
volume={63}, 
number={12}, 
pages={2998-3011}, 
keywords={cache storage;circuit complexity;content-addressable storage;embedded systems;probability;CRTES domain;PTA-compliant cache design;WCET analysis tools;cache memories;critical real-time embedded systems;direct-mapped arrangements;energy consumption;hardware complexity;hardware design;high-performance features;parametric random placement policy;probabilistic timing analysis;probabilistically analysable real-time systems;program cache accesses;set-associative arrangements;trustworthy-tight WCET estimates;trustworthy-tight worst-case execution time estimates;Hardware;Layout;Probabilistic logic;Program processors;Random variables;Real-time systems;Cache memories;worst-case analysis}, 
doi={10.1109/TC.2013.182}, 
ISSN={0018-9340}, 
month={Dec},}

@MANUAL{DO178B,
  title = {{DO-178B} / {ED-12B}, Software Considerations in Airborne Systems and Equipment Certification},
  author = {{RTCA and EUROCAE}},
  year = 1992,
}

@MANUAL{ISO26262,
  title = {{ISO/DIS 26262}. Road Vehicles -- Functional Safety},
  author = {{International Organization for Standardization}},
  year = 2009,
}

@misc{MBPTACV-script,
  author       = {Abella, Jaume},
  title        = {MBPTA-CV},
  month        = nov,
  year         = 2017,
  doi          = {10.5281/zenodo.1065776},
  url          = {https://doi.org/10.5281/zenodo.1065776}
}

@article{MBPTACV,
 author = {Cazorla, Francisco J. and Kosmidis, Leonidas and Mezzetti, Enrico and Hernandez, Carles and Abella, Jaume and Vardanega, Tullio},
 title = {Probabilistic Worst-Case Timing Analysis: Taxonomy and Comprehensive Survey},
journal = {ACM Comput. Surv.},
year = {2019},
} 

%@article{MBPTACV,
% author = {Cazorla, Francisco J. and Kosmidis, Leonidas and Mezzetti, Enrico and Hernandez, Carles and Abella, Jaume and Vardanega, Tullio},
% title = {Probabilistic Worst-Case Timing Analysis: Taxonomy and Comprehensive Survey},
% journal = {ACM Comput. Surv.},
% issue_date = {February 2019},
%} 


% If more than three authors, use short format for the author's list: <First_Author et al.>
@IEEEtranBSTCTL{bstctl:etal,
  CTLuse_forced_etal = {yes},
  CTLmax_names_forced_etal = {2},
}

@IEEEtranBSTCTL{bstctl:nodash,
  CTLdash_repeated_names = {no},
}

% Manuals, applications and MareNostrum
%@inproceedings{Euroserver,
% author = {Durand et al., Yves},
% title = {{EUROSERVER: Energy Efficient Node for European Micro-servers}},
% booktitle = {Proceedings of the 17th Euromicro Conference on Digital Systems Design (DSD)},
% year = {2014}
%}

@misc{Pritom,
  author       = {Asifuzzaman, Kazi},
  issn         = {1650-2884},
  series       = {LU-CS-EX 2013-27},
  title        = {Design and Implementation of an Embedded Vision System for Industrial Robots},
  year         = {2013},
}




@article{CACTI,
    author = {Naveen Muralimanohar and Rajeev Balasubramonian and Norman P. Jouppi},
    title = {{CACTI 6.0: A Tool to Understand Large Caches}},
    journal = {{HP Technical Report HPL-2009-85}},
    year = {2009}
}

@INPROCEEDINGS{Augustine:STT-MTJNumericalAnalysis, 
author={Augustine, C. and Raychowdhury, A. and Somasekhar, D. and Tschanz, J. and Roy, K. and De, V.K.}, 
booktitle={{IEEE International Electron Devices Meeting (IEDM)}}, 
title={{Numerical Analysis of Typical STT-MTJ Stacks for 1T-1R Memory Arrays}}, 
year={2010}, 
}

@article{MezaNVMRowBuffer,
 author = {Justin Meza, Jing Li and Onur Mutlu},
 title = {{Evaluating Row Buffer Locality in Future Non-Volatile Main Memories}},
 journal = {{Safari Technical Report No. 2012-002}},
 year = {2012},}


@inproceedings{Pajouhi:ECC-4-STTMRAM,
 author = {Pajouhi, Zoha and Fong, Xuanyao and Roy, Kaushik},
 title = {{Device/Circuit/Architecture Co-design of Reliable STT-MRAM}},
 booktitle = {{Proceedings of the Design, Automation \& Test in Europe Conference \& Exhibition}},
 year = {2015},
} 

@misc{EverspinPress,
    author = {{Everspin Technologies, Inc.}},
    title={{Everspin Enhances RIM Smart Meters with Instantly Non-Volatile,
 Low-Energy MRAM  Memory}},
    howpublished = "http://www.everspin.com/everspin-embedded-mram"
}


@misc{ITRS2013,
    author = {{Iternational Technology Roadmap for Semiconductors}},
    title={{ITRS 2013 Edition}},
    howpublished = "http://www.itrs.net/reports.html"
}

@INPROCEEDINGS{Sun:HPCA2009, 
author={Guangyu Sun and Xiangyu Dong and Yuan Xie and Jian Li and Yiran Chen}, 
booktitle={IEEE 15th International Symposium on High Performance Computer Architecture}, 
title={{A Novel Architecture of the 3D Stacked MRAM L2 Cache for CMPs}}, 
year={2009}, 
}



@INPROCEEDINGS{Halupka:NegativeResistanceSTT, 
author={Halupka, D. and Huda, S. and Song, W. and Sheikholeslami, A. and Tsunoda, K. and Yoshida, C. and Aoki, M.}, 
booktitle={{IEEE International Solid State Circuits Conference}}, 
title={{Negative-Resistance Read and Write Schemes for STT-MRAM in 0.13um CMOS}}, 
year={2010}, 
}

@misc{EverspinProd,
    author = {{Everspin Technologies, Inc.}},
    title={{Everspin Embedded MRAM}},
    howpublished = "http://www.everspin.com/everspin-embedded-mram"
}


@INPROCEEDINGS{ToshibaAdvMTJ1, 
author={Abe, K. and Noguchi, H. and Kitagawa, E. and Shimomura, N. and Ito, J. and Fujita, S.}, 
booktitle={{IEEE International Electron Devices Meeting (IEDM)}}, 
title={{Novel Hybrid DRAM/MRAM Design for Reducing Power of High Performance Mobile CPU}}, 
year={2012}, 

}

@INPROCEEDINGS{ToshibaAdvMTJ2, 
author={Noguchi, H. and Kushida, K. and Ikegami, K. and Abe, K. and Kitagawa, E. and Kashiwada, S. and Kamata, C. and Kawasumi, A. and Hara, H. and Fujita, S.}, 
booktitle={Symposium on VLSI Technology (VLSIT)}, 
title={{A 250-MHz 256b-I/O 1-Mb STT-MRAM with Advanced Perpendicular MTJ Based Dual cell for Nonvolatile Magnetic Caches to Reduce Active Power of Processors}}, 
year={2013}, 
}


@INPROCEEDINGS{ToshibaAdvMTJ3, 
author={Nebashi, R. and Sakimura, N. and Honjo, H. and Saito, S. and Ito, Y. and Miura, S. and Kato, Y. and Mori, K. and Ozaki, Y. and Kobayashi, Y. and Ohshima, N. and Kinoshita, K. and Suzuki, T. and Nagahara, K. and Ishiwata, N. and Suemitsu, K. and Fukami, S. and Hada, H. and Sugibayashi, T. and Kasai, N.}, 
booktitle={IEEE International Solid-State Circuits Conference}, 
title={{A 90nm 12ns 32Mb 2T1MTJ MRAM}}, 
year={2009}, 

}



@misc{Darpa:ExaScale,
 author = {Peter Kogge and Keren Bergman and Shekhar Borkar and Dan Campbell and William Carlson and William Dally and Monty Denneau and Paul Franzon and William Harrod and Kerry Hill and Jon Hiller and Sherman Karp and Stephen Keckler and Dean Klein and Robert Lucas and Mark Richards and Al Scarpelli and Steven Scott and Allan Snavely and Thomas Sterling and R. Stanley Williams and Katherine Yelick},
 title = {{ExaScale Computing Study: Technology Challenges in Achieving Exascale Systems}},
 organization = {DARPA},
 month = sep,
 year = 2008
}

@misc{Intel:ExaScale,
 author = {Avinash Sodani},
 title = {{Race to Exascale: Opportunities and Challenges}},
 howpublished = {Keynote Presentation at the 44th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
 month = dec,
 year = 2011
}

@misc{DOE:ExaScale,
 author = {Rick Stevens and Andy White and Pete Beckman and Ray Bair-ANL and Jim Hack and Jeff Nichols and Al GeistORNL and Horst Simon and Kathy Yelick and John Shalf-LBNL and Steve Ashby and Moe Khaleel-PNNL and Michel McCoy and Mark Seager and Brent Gorda-LLNL and John Morrison and Cheryl Wampler-LANL and James Peery and Sudip Dosanjh and Jim Ang-SNL and Jim Davenport and Tom Schlagel and BNL and Fred Johnson and Paul Messina},
 title = {{A Decadal DOE Plan for Providing Exascale Applications and Technologies for DOE Mission Needs}},
 howpublished = {Presentation at Advanced Simulation and Computing Principal Investigators Meeting},
 month = mar,
 year = 2010
}

%@article{MezaBaal,
% author = {Justin Meza, Jing Li and Onur Mutlu},
% title = {{Evaluating Row Buffer Locality in Future Non-Volatile Main Memories}},
% journal = {{Safari Technical Report No. 2012-002}},
% year = {2012},
%
%}

@article{Paul,
 author = {Paul H Hargrove and Jason C Duell},
 title = {{Berkeley Lab Checkpoint/Restart (BLCR) for Linux Clusters}},
 journal = {{Journal of Physics}},
 year = {2006},

}

%: Conf. Ser. 46 494 

@INPROCEEDINGS{Oldfield, 
author={Oldfield, R.A. and Arunagiri, S. and Teller, P.J. and Seelam, S. and Varela, M.R. and Riesen, R. and Roth, P.C.}, 
booktitle={{24th IEEE Conference on Mass Storage Systems and Technologies}}, 
title={{Modeling the Impact of Checkpoints on Next-Generation Systems}}, 
year={2007}, 
}

@article{Ferreira,
  title={{Increasing Fault Resiliency in a Message-Passing Environment}},
  author={Ferreira, Kurt and Riesen, Rolf and Oldfield, Ron and Stearley, Jon and Laros, James and Pedretti, Kevin and Kordenbrock, Todd and Brightwell, Ron},
  journal={Sandia National Laboratories, Tech. Rep.},
  year={2009}
}
%SAND2009-6753

@article{Daly:nuclear,
 author = {John T. Daly},
 title = {{ADTSC Nuclear Weapons Highlights: Facilitating High Throughput ASC Calculations}},
 journal = {Technical Report LALP-07-041, Los Alamos National Laboratory, Los Alamos, NM, USA},
 year = {2007},

} 


@inproceedings{Daly:MTTF,
 author = {John T. Daly and Lori A. Pritchett-Sheats and Sarah E. Michalak},
 title = {{Application MTTFE vs. Platform MTTF: A Fresh Perspective on System
Reliability and Application Throughput for Computations at Scale}},
 booktitle = {Workshop on Resiliency in High Performance Computing},
 year = {2008},

} 



@article{Elnozahy,
 author = {Elnozahy, E. N. (Mootaz) and Alvisi, Lorenzo and Wang, Yi-Min and Johnson, David B.},
 title = {{A Survey of Rollback-recovery Protocols in Message-passing Systems}},
 journal = {ACM Comput. Surv.},
 year = {2002},

} 

@inproceedings{Jian,
 author = {Jian, Xun and Duwe, Henry and Sartori, John and Sridharan, Vilas and Kumar, Rakesh},
 title = {{Low-power, Low-storage-overhead Chipkill Correct via Multi-line Error Correction}},
 booktitle = {{International Conference on High Performance Computing, Networking, Storage and Analysis}},
 year = {2013},} 


@INPROCEEDINGS{Kim, 
author={Yoongu Kim and Daly, R. and Kim, J. and Fallin, C. and Ji Hye Lee and Donghyuk Lee and Wilkerson, C. and Lai, K. and Mutlu, O.}, 
booktitle={{ACM/IEEE 41st International Symposium on Computer Architecture (ISCA)}}, 
year = {2014},
title={{Flipping Bits in Memory without Accessing them: An Experimental Study of DRAM Disturbance Errors}},}


@inproceedings{Bianca,
 author = {Schroeder, Bianca and Pinheiro, Eduardo and Weber, Wolf-Dietrich},
 title = {{DRAM Errors in the Wild: A Large-scale Field Study}},
 booktitle = {{11th International Joint Conference on Measurement and Modeling of Computer Systems}},
 year = {2009},

}

@INPROCEEDINGS{Hwang,
    author = {Andy A. Hwang and Ioan Stefanovici and Bianca Schroeder},
    title = {{Cosmic Rays Don’t Strike Twice: Understanding the Nature of DRAM Errors and the Implications for System Design}},
    booktitle = {17th International Conference on Architectural Support for Programming Languages and Operating Systems},
    year = {2012}
}

@inproceedings{Sridharan,
 author = {Sridharan, Vilas and Liberty, Dean},
 title = {{A Study of DRAM Failures in the Field}},
 booktitle = {{International Conference on High Performance Computing, Networking, Storage and Analysis}},
 year = {2012},}
 
@inproceedings{SridharanSC,
 author = {Sridharan, Vilas and Stearley, Jon and DeBardeleben, Nathan and Blanchard, Sean and Gurumurthi, Sudhanva},
 title = {{Feng Shui of Supercomputer Memory: Positional Effects in DRAM and SRAM Faults}},
 booktitle = {{International Conference on High Performance Computing, Networking, Storage and Analysis}},
 year = {2013},} 

 

@INPROCEEDINGS{SenniFR, 
author={Senni, S. and Torres, L. and Sassatelli, G. and Bukto, A. and Mussard, B.}, 
booktitle={IEEE Computer Society Annual Symposium on VLSI (ISVLSI)}, 
title={{Exploration of Magnetic RAM Based Memory Hierarchy for Multicore Architecture}}, 
year={2014}, }

@ARTICLE{XiePenn, 
author={Yuan Xie}, 
journal={IEEE Design Test of Computers}, 
title={{Modeling, Architecture, and Applications for Emerging Memory Technologies}}, 
year={2011},}


@misc{SamsungPatent1,
  title={{Magneto-resistive memory device including source line voltage generator}},
  author={Kim, H. and Kang, S.K. and SOHN, D.H. and Kim, D.M. and Lee, K.C.},
  year={2013},
  publisher={Google Patents},
 
}


@misc{SamsungPatent2,
  title={{Resistive Memory Device, System Including the Same and Method of Reading Data in the Same}},
  author={Oh, H.R.},
  year={2014},
  publisher={Google Patents},
}

@misc{SamsungPatent3,
  title={{Magnetic Random Access Memory}},
  author={Kim, C. and Kang, D. and Kim, H. and Park, C.W. and SOHN, D.H. and Lee, Y.S. and Kang, S. and Oh, H.R. and Cha, S.},
  year={2013},
  publisher={Google Patents},
}

 

@INPROCEEDINGS{Hosomi, 
author={Hosomi, M. and Yamagishi, H. and Yamamoto, T. and Bessho, K. and Higo, Y. and Yamane, K. and Yamada, H. and Shoji, M. and Hachino, H. and Fukumoto, C. and Nagao, H. and Kano, H.}, 
booktitle={{IEEE International Electron Devices Meeting}},
year = {2005}, 
title={{A Novel Nonvolatile Memory with Spin Torque Transfer Magnetization Switching: Spin-RAM}}, }

@article{KatinePillars99,
  title = {{Current-Driven Magnetization Reversal and Spin-Wave Excitations in Co $/$Cu $/$Co Pillars}},
  author = {Katine, J. A. and Albert, F. J. and Buhrman, R. A. and Myers, E. B. and Ralph, D. C.},
  journal = {Phys. Rev. Lett.},
  year = {2000},
}

@ARTICLE{SpongValve96, 
author={Spong, J.K. and Speriosu and Fontana, Robert E. and Dovek, Moris M. and Hylton, T.L.}, 
journal={IEEE Transactions on Magnetics}, 
title={{Giant Magnetoresistive Spin Valve Bridge Sensor}}, 
year={1996},}

@article{DienySoft91,
  title = {{Giant magnetoresistive in soft ferromagnetic multilayers}},
  author = {Dieny, B. and Speriosu, V. S. and Parkin, S. S. P. and Gurney, B. A. and Wilhoit, D. R. and Mauri, D.},
  journal = {Phys. Rev. B},
  year = {1991},

}


@article{Sally,
 author = {Wulf, Wm. A. and McKee, Sally A.},
 title = {{Hitting the Memory Wall: Implications of the Obvious}},
 journal = {SIGARCH Comput. Archit. News},
 month = mar,
 year = {1995},

}



@PhdThesis{IshwarPhD,
title = "{{Scalable and Energy Efficient DRAM Refresh Techniques}}",
author = "Ishwar Singh Bhati",
school = "University of Maryland, College Park",
year = "2014",
}

@INPROCEEDINGS{IshwarDRAM, 
author={Bhati, Ishwar and Chang, Mu-Tien and Chishti, Zeshan and Lu, Shih-Lien and Jacob, Bruce}, 
booktitle={IEEE Transactions on Computers}, 
title={{DRAM Refresh Mechanisms, Penalties, and Trade-Offs}}, 
year={2015},}

@inproceedings{LiuRAIDR,
 author = {Liu, Jamie and Jaiyen, Ben and Veras, Richard and Mutlu, Onur},
 title = {{RAIDR: Retention-Aware Intelligent DRAM Refresh}},
 booktitle = {39th Annual International Symposium on Computer Architecture},
 year = {2012},} 



@INPROCEEDINGS{Suresh, 
author={Suresh, A. and Cicotti, P. and Carrington, L.}, 
booktitle={{IEEE International Conference on Cluster Computing (CLUSTER)}},
year = {2014}, 
title={{Evaluation of Emerging Memory Technologies for HPC, Data Intensive Applications}},}

@article {Vetter,
	title = {{Opportunities for Nonvolatile Memory Systems in Extreme-Scale High Performance Computing}},
	journal = {Computing in Science and Engineering special issue},
	year = {2015},
	author = {Jeffrey S. Vetter and Sparsh Mittal},
}

@INPROCEEDINGS{Li:Hybrid, 
author={Jianhua Li and Xue, C.J. and Yinlong Xu}, 
booktitle={IEEE/IFIP 19th International Conference on VLSI and System-on-Chip (VLSI-SoC)},
year = {2011}, 
title={{STT-RAM Based Energy-Efficiency Hybrid Cache for CMPs}},}


@INPROCEEDINGS{Zhou, 
author={Ping Zhou and Bo Zhao and Jun Yang and Youtao Zhang}, 
booktitle={IEEE/ACM International Conference on Computer-Aided Design - Digest of Technical Papers},
year = {2009}, 
title={{Energy Reduction for STT-RAM Using Early Write Termination}}, }


@INPROCEEDINGS{Jog, 
author={Jog, A. and Mishra, A.K. and Cong Xu and Yuan Xie and Narayanan, V. and Iyer, R. and Das, C.R.}, 
booktitle={49th ACM/EDAC/IEEE Design Automation Conference (DAC)},
year = {2012}, 
title={{Cache Revive: Architecting Volatile STT-RAM Caches for Enhanced Performance in CMPs}},}

@INPROCEEDINGS{Jin, 
author={Youngbin Jin and Mustafa Shihab and Myoungsoo Jung}, 
title={{Area, Power, and Latency Considerations of STT-MRAM to Substitute for Main Memory}},
booktitle={{41st International Symposium on Computer Architecture (ISCA)}},  
year={2014}, }

@misc{Paraver,
    author = {{Barcelona Supercomputing Center}},
    title = {Paraver},
    howpublished = "http://www.bsc.es/computer-sciences/performance-tools/paraver"
}

@misc{Extrae,
    author = {{Barcelona Supercomputing Center}},
    title = {Extrae},
    howpublished = "http://www.bsc.es/computer-sciences/extrae"
}

@manual{PRACE_del,
    title     = {{Unified European Applications Benchmark Suite}},
    organization = {Partnership for Advanced Computing in Europe (PRACE)},
    year      = {2013},}

@misc{website:mn,
    author = {{Barcelona Supercomputing Center}},
    title = {Mare{N}ostrum {I}{I}{I} {S}ystem {A}rchitecture},
    year = {2013},
    howpublished = "http://www.bsc.es/marenostrum-support-services/mn3"
}

@misc{Valgrind,
    title = {Valgrind},
    howpublished = "http://valgrind.org/"
}


@article{Rico,
 author = {Rico, Alejandro and Cabarcas, Felipe and Villavieja, Carlos and Pavlovic, Milan and Vega, Augusto and Etsion, Yoav and Ramirez, Alex and Valero, Mateo},
 title = {{On the Simulation of Large-scale Architectures Using Multiple Application Abstraction Levels}},
 journal = {ACM Trans. Archit. Code Optim.},
 year = {2012},

} 


@misc{Intel64,
    author = {{Intel}},
    title = {{Intel® 64 and IA-32 Architectures Optimization Reference Manual}},
    year = {},
    howpublished = "http://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-optimization-manual.html"
}


@INPROCEEDINGS{Onur, 
author={Kultursay, E. and Kandemir, M. and Sivasubramaniam, A. and Mutlu, O.}, 
booktitle={{IEEE International Symposium on Performance Analysis of Systems and Software}},
year = {2013}, 
title={{Evaluating STT-RAM as an Energy-Efficient Main Memory Alternative}}, } 

@INPROCEEDINGS{MilanICCD, 
author={Pavlovic, M. and Puzovic, N. and Ramirez, A.}, 
booktitle={IEEE 31st International Conference on Computer Design}, 
title={{Data Placement in HPC Architectures with Heterogeneous Off-Chip Memory}}, 
year={2013}, }


@misc{Top500,
    author = {{Top500}},
    title = {{Top500 Supercomuter Sites}},
    howpublished = "http://www.top500.org/"
}

@INPROCEEDINGS{MPIPat, 
author={Preissl, R. and Kockerbauer, T. and Schulz, M. and Kranzlmuller, D. and Supinski, B. and Quinlan, D.J.}, 
booktitle={{37th International Conference on Parallel Processing}}, 
year = {2008},
title={{Detecting Patterns in MPI Communication Traces}}, }


@INPROCEEDINGS{MPIpat2, 
author={Alawneh, L. and Hamou-Lhadj, A.}, 
booktitle={IEEE 20th International Conference on Program Comprehension}, 
year = {2012},
title={{Identifying Computational Phases from Inter-Process Communication Traces of HPC Applications}},}


@ARTICLE{Li, 
author={Hai Li and Xiaobin Wang and Zhong-Liang Ong and Weng-Fai Wong and Yaojun Zhang and Peiyuan Wang and Yiran Chen}, 
journal={IEEE Transactions on Magnetics}, 
title={{Performance, Power, and Reliability Tradeoffs of STT-RAM Cell Subject to Architecture-Level Requirement}}, 
year={2011}, 
}


@inproceedings{Sun,
 author = {Sun, Zhenyu and Bi, Xiuyuan and Li, Hai (Helen) and Wong, Weng-Fai and Ong, Zhong-Liang and Zhu, Xiaochun and Wu, Wenqing},
 title = {{Multi Retention Level STT-RAM Cache Designs with a Dynamic Refresh Scheme}},
 booktitle = {44th Annual IEEE/ACM International Symposium on Microarchitecture},
 year = {2011},}
 
 
 @INPROCEEDINGS{Smullen, 
author={Smullen, C.W. and Mohan, V. and Nigam, A. and Gurumurthi, S. and Stan, M.R.}, 
booktitle={IEEE 17th International Symposium on High Performance Computer Architecture (HPCA)},
year = {2011}, 
title={{Relaxing non-volatility for fast and energy-efficient STT-RAM caches}}, } 


@article{Uhlig:1997:TMS:254180.254184,
 author = {Uhlig, Richard A. and Mudge, Trevor N.},
 title = {{Trace-driven Memory Simulation: A Survey}},
 journal = {ACM Comput. Surv.},
 year = {1997},

}


%@article{10.1109/ICPP.2008.71,
%author = {Robert Preissl and Thomas Kockerbauer and Martin Schulz and Dieter Kranzlm and Bronis R. de Supinski and Daniel J. Quinlan},
%title = {{Detecting Patterns in MPI Communication Traces}},
%journal ={42nd International Conference on Parallel Processing},
%year = {2013},
%}

@inproceedings{limpio,
author={Pavlovic, Milan and Radulovic, Milan and Ramirez, Alex and Radojkovic, Petar},
title = {{Limpio --- LIghtweight MPI instrumentatiOn}},
booktitle = {IEEE 23rd International Conference on Program Comprehension},
year = {2015},
url = {http://www.bsc.es/computer-sciences/computer-architecture/memory-systems/limpio}
}

@phdthesis{Puzak:1985:ACR:911778,
 author = {Puzak, Thomas Roberts},
 title = {{Analysis of Cache Replacement Algorithms}},
 year = {1985},
 publisher = {University of Massachusetts Amherst},
}

@article{Wang:1991:ETS:128738.128740,
 author = {Wang, Wen-Hann and Baer, Jean-Loup},
 title = {{Efficient Trace-driven Simulation Methods for Cache Performance Analysis}},
 journal = {ACM Trans. Comput. Syst.},
 year = {1991},

}

%%author = {Rick Stevens and Andy White et al.},
%@manual{DOE:ExaScale,
% author = {Stevens et al., Rick},
% title = {{A Decadal DOE Plan for Providing Exascale Applications and Technologies for DOE Mission Needs}},
% organization = {Presentation at Advanced Simulation and Computing Principal Investigators Meeting},
% year = {2010}
%}
%
%@manual{ETP4HPC,
%    title = {ETP4HPC Strategic Research Agenda Achieving HPC leadership in Europe},
%    organization = {European Technology Platform for High Performance Computing},
%    year = {2013}
%}
%
%@manual{IBM:LSF,
% author = {IBM},
% title = {{Administering Platform LSF}},
% organization = {Version 9 Release 1.2},
% year = {2014}
%} 
%
%@techreport{Asanovic:Berkeley-2006,
% author = {Asanovic et al., Krste},
% title = {{The Landscape of Parallel Computing Research: A View from Berkeley}},
% Institution = {EECS Department, University of California, Berkeley},
% Number = {UCB/EECS-2006-183},
% year = {December, 2006}
%} 
%
%@misc{website:mn,
%    author = {{Barcelona Supercomputing Center}},
%    title = {Mare{N}ostrum {I}{I}{I} {S}ystem {A}rchitecture},
%    year = {2013},
%    howpublished = "http://www.bsc.es/marenostrum-support-services/mn3"
%}
%
%@misc{website:prace,
%    author = {{Partnership for Advanced Computing in Europe (PRACE)}},
%    title = {Prace Research Infrastructure},
%    year = {},
%    howpublished = "http://www.prace-ri.eu"
%}
%
%@misc{website:specmpi2007,
%    author = {},
%    title = {{SPEC MPI2007}},
%    year = {},
%    howpublished = "http://www.spec.org/mpi2007/"
%}
%
%@misc{website:specomp2012,
%    author = {},
%    title = {{SPEC OMP2012}},
%    year = {},
%    howpublished = "https://www.spec.org/omp2012/"
%}
%
%@misc{website:spec,
%    author = {},
%    title = {{SPEC} {B}enchmarks},
%    year = {},
%    howpublished = "https://www.spec.org/"
%}
%
%@misc{website:sequoiabench,
%    author = {},
%    title = {{ASC} {S}equoia {B}enchmarks {C}odes},
%    year = {},
%    howpublished = "https://asc.llnl.gov/sequoia/benchmarks/"
%}
%@misc{website:LINPACK,
%    author = {},
%    title = {{LINPACK} {HPC} {B}enchmark},
%    year = {},
%    howpublished = "http://www.netlib.org/linpack/"
%}
%
%@misc{website:Graph500,
%    author = {},
%    title = {{Graph 500}},
%    year = {},
%    howpublished = "http://www.graph500.org/"
%}
%
%@misc{website:TOP500,
%    author = {},
%    title = {{TOP500 List}},
%    year = {November 2014},
%    howpublished = "http://www.top500.org/"
%}
%
%@manual{Extrae,
%    title = {{E}xtrae {U}ser guide manual for version 2.5.1},
%    organization = {Barcelona Supercomputing Center},
%    year = {April, 2014}
%}
%
%%Papers
%
%author = {Yves Durand and Paul M. Carpenter and Stefano Adami and Angelos Bilas and Denis Dutoita and Alexis Farcy and Georgi Gaydadjiev and John Goodacre and Manolis Katevenis and Manolis Marazakis and Emil Matus and Iakovos Mavroidis and John Thomson},

%@inproceedings{Murphy:CUG-2010,
% author = {Murphy et al., Richard},
% title = {{Introducing the Graph 500}},
% booktitle = {Cray User's Group (CUG)},
% year = {2010}
%}
%
%@inproceedings{Murphy:IISWC-2006,
% author = {Murphy et al., Richard},
% title = {{DFS: A Simple to Write Yet Difficult to Execute Benchmark}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2006}
%} 
%
%%author = {Milan Pavlovic et al.},
%%author = {Pavlovic, Milan and Etsion, Yoav and Ramirez, Alex},
%@inproceedings{Pavlovic:IISWC-2011,
% author = {Pavlovic et al., Milan},
% title = {{On the Memory System Requirements of Future Scientific Applications: Four Case-studies}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2011}
%} 
%
%%author = {Seelam, Seetharami and Chung, I-Hsin and Cong, Guojing and Wen, Hui-Fang and Klepacki, David},
%@inproceedings{Seelam:HPCC-2008,
% author = {Seelam et al., Seetharami},
% title = {{Workload Performance Characterization of DARPA HPCS Benchmarks}},
% booktitle = {The 10th IEEE International Conference on High Performance Computing and Communications (HPCC)},
% year = {2008}
%} 
%
%
%% author = {Maron, Bill and Chen, Thomas and Vianney, Duc and Olszewski, Bret and Kunkel, Steve and Mericas, Alex},
%@inproceedings{Maron:IISWC-2005,
% author = {Maron et al., Bill},
% title = {{Workload Characterization for the Design of Future Servers}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2005}
%} 
%
%
%% author = {Barroso, Luiz Andre and Gharachorloo, Kourosh and Bugnion, Edouard},
%@inproceedings{Barroso:ISCA-1998,
% author = {Luiz Andre Barroso et al.},
% title = {{Memory System Characterization of Commercial Workloads}},
% booktitle = {Proceedings of the 25th Annual International Symposium on Computer Architecture (ISCA)},
% year = {1998}
%}
%
%%author = {Jaleel, Aamer and Mattina, Matthew and Jacob, Bruce},
%@inproceedings{Jaleel:HPCA-2006,
% author = {Aamer Jaleel et al.},
% title = {{Last Level Cache (LLC) Performance of Data Mining Workloads On a CMP — A Case Study of Parallel Bioinformatics Workloads}},
% booktitle = {Proceedings of the 12th International Symposium on High-Performance Computer Architecture (HPCA)},
% year = {2006}
%}
%
%@article{Murphy:ToC-2007,
% author = {Murphy, Richard and Kogge, Peter},
% title = {{On the Memory Access Patterns of Supercomputer Applications: Benchmark Selection and Its Implications}},
% journal = {IEEE Transactions on Computers},
% volume = {Vol. 56},
% year = {2007}
%}
%
%@article{Dongarra:2011,
% author = {Dongarra et al., Jack},
% title = {{The International Exascale Software Project roadmap}},
% journal = {International Journal of High Performance Computing Applications},
% year = {2011}
%}
%
%@article{Ranganathan:2011,
% author = {Parthasarathy Ranganathan},
% title = {{From Microprocessors to Nanostores: Rethinking Data-Centric Systems}},
% journal = {Computer},
% volume = {Vol. 44, Issue: 1},
% year = {2011}
%}
%@inproceedings{Murphy:IISWC-2005,
% author = {Murphy, Richard},
% title = {{On the Effects of Memory Latency and Bandwidth on Supercomputer Application Performance}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2005}
%} 
%
%%author = {Ishizaki, Kazuaki and Nakatani, Toshio and Daijavad, Shahrokh},
%@inproceedings{Ishizaki:IISWC-2009,
% author = {Ishizaki et al., Kazuaki},
% title = {{Analyzing and Improving Performance Scalability of Commercial Server Workloads on a Chip Multiprocessor}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2009}
%} 
%
%%author = {Biswas, Susmit and Supinski, Bronis R. de and Schulz, Martin and Franklin, Diana and Sherwood, Timothy and Chong, Frederic T.},
%@inproceedings{Biswas:IPDPS-2011,
% author = {Biswas et al., Susmit},
% title = {{Exploiting Data Similarity to Reduce Memory Footprints}},
% booktitle = {Proceedings of the IEEE International Parallel \& Distributed Processing Symposium (IPDPS)},
% year = {2011}
%} 
%
%@inproceedings{Alameldeen:ISCA-2004,
% author = {Alameldeen, Alaa R. and Wood, David A.},
% title = {{Adaptive Cache Compression for High-Performance Processors}},
% booktitle = {Proceedings of the 31st Annual International Symposium on Computer Architecture (ISCA)},
% year = {2004}
%}
% 
%%author = {Wilson, Paul R. and Kaplan, Scott F. and Smaragdakis, Yannis},
%@inproceedings{Wilson:Usenix-1999,
% author = {Paul R. Wilson et al.},
% title = {{The Case for Compressed Caching in Virtual Memory Systems}},
% booktitle = {Proceedings of the USENIX Annual Technical Conference},
% year = {1999}
%}
%
%%author = {Alam, Sadaf R. and  Barrett, Richard F. and Kuehn, Jeffery A. and Roth, Philip C. and Vetter, Jeffrey S.},
%@inproceedings{Alam:IISWC-2006,
% author = {Alam et al., Sadaf R.},
% title = {{Characterization of Scientific Workloads on Systems with Multi-Core Processors}},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2006}
%}
%
%%author = {Woo, Steven Cameron and Ohara, Moriyoshi and Torrie, Evan},
%@inproceedings{Woo:ISCA-1995,
% author = {Woo et al., Steven Cameron},
% title = {{The SPLASH-2 Programs: Characterization and Methodological Considerations}},
% booktitle = {Proceedings of the 22nd Annual International Symposium on Computer Architecture (ISCA)},
% year = {1995}
%}
%
%% author = {Bhadauria, Major and  Weaver, Vincent M. and McKee, Sally A.},
%@inproceedings{Bhadauria:IISWC-2009,
% author = {Bhadauria et al., Major},
% title = {Understanding PARSEC Performance on Contemporary CMPs},
% booktitle = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
% year = {2009}
%}
%
%% author = {Beinia, Christian and  Kumar, Sanjeev and Singh, Jaswinder Pal and Li, Kai},
%@inproceedings{Beinia:PACT-2008,
% author = {Beinia et al., Christian},
% title = {{The PARSEC Benchmark Suite: Characterization and Architectural Implications}},
% booktitle = {Proceedings of the 17th international conference on Parallel Architectures and Compilation Techniques (PACT)},
% year = {2008}
%}
%
%% author = {Burger, Doug and Goodman, James R. and Kagi, Alain},
%@inproceedings{Burger:ISCA-1996,
% author = {Doug Burger et al.},
% title = {{Memory Bandwidth Limitations of Future Microprocessors}},
% booktitle = {Proceedings of the 23th Annual International Symposium on Computer Architecture (ISCA)},
% year = {1996}
%}
%
%% author = {Wong, Frederick C. and  Martin, Richard P. and Arpaci-Dusseau, Remzi H. and Culler, David E.},
%@inproceedings{Wong:SC-1999,
% author = {Wong  et al., Frederick C.},
% title = {{Architectural Requirements and Scalability of the NAS Parallel Benchmarks}},
% booktitle = {Proceedings of the ACM/IEEE conference on Supercomputing (SC)},
% year = {1999}
%}
%
%% author = {Trancoso, Pedro and Larriba-Pey, Josep-L. and Zhang, Zheng and Torrellas, Josep},
%@inproceedings{Trancoso:HPCA-1997,
% author = {Pedro Trancoso et al.},
% title = {{The Memory Performance of DSS Commercial Workloads in Shared-Memory Multiprocessors}},
% booktitle = {Proceedings of the 3rd International Symposium on High-Performance Computer Architecture (HPCA)},
% year = {1997}
%}
%
%@inproceedings{Koop:CCGRID-2007,
% author = {Koop et al., Matthew J. },
% title = {{Reducing Connection Memory Requirements of MPI for InfiniBand Clusters: A Message Coalescing Approach}},
% booktitle = {Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGRID)},
% year = {2007}
%}
%
%% author = {Perks, O. and Hammond, S. D. and Pennycook, S. J. and Jarvis, S. A.}, ACM SIGMETRICS Performance Evaluation Review - Special issue on the 1st international %workshop on performance modeling, benchmarking and simulation of high performance computing systems (PMBS '10)
%@article{Perks:PMBS-2011,
% author = {Perks et al., O.},
% title = {{Should We Worry About Memory Loss?}},
% journal = {ACM SIGMETRICS Performance Evaluation Review - Special issue on the workshop on PMBS},
% volume = {Vol. 38 Issue 4},
% year = {2011}
%}
%
%@article{Dubey:Intel-2005,
% author = {Dubey, Pradeep},
% title = {{Recognition, Mining and Synthesis Moves Computers to the Era of Tera}},
% journal = {Intel Technology Journal},
% year = {February, 2005}
%}
%
%@article{Amarasinghe:DARPA-2009,
% author = {Amarasinghe et. al., Saman},
% title = {{ExaScale Software Study: Software Challenges in Extreme Scale Systems}},
% journal = {DARPA},
% year = {September, 2009}
%}
%
%@article{HPC_Challenge:2005,
% author = {Luszczek, Piotr and Dongarra, Jack J.},
% title = {{Introduction to the HPC Challenge Benchmark Suite}},
% journal = {ICL Technical Report, ICL-UT-05-01},
% year = {2005}
%}
%@article{STREAM:1997,
% author = {McCalpin, John D.},
% title = {{STREAM: Sustainable Memory Bandwidth in High Performance Computers}},
% journal = {Report, University of Virginia},
% year = {1997}
%}
%
%@article{HBM:JEDEC2013,
% author = {{JEDEC Solid State Technology Association}},
% title = {{High Bandwidth Memory (HBM) DRAM}},
% journal = {JESD235},
% year = {2013},
% month = {October}
%}
%
%@article{HMC:2014,
% author = {{Hybrid Memory Cube Consortium}},
% title = {{Hybrid Memory Cube Specification 1.1}},
% journal = {},
% year = {2014}
%}
%
%%author = {Duran, Alejandro and Ayguade, Eduard and Badia, Rosa M. and Labarta, Jesus and Martinell, Luis and Martorell, Xavier and Planas, Judit},
%@article{OmpSs:PPL-2011,
% author = {Duran et al., Alejandro},
% title = {{OmpSs: A Proposal for Programming Heterogeneous Multi-core Architectures}},
% journal = {Parallel Processing Letters},
% volume = {Volume 21, Issue 02},
% year = {2011}
%}

@TECHREPORT{West2009NASA,
  author 			= {Adam West},
  title 			= {{NASA Study on Flight Software Complexity. Final Report}},
  institution = {NASA},
  year 				= {2009},
}

@Misc{ARM100x,
  author 			= {{ARM}},
  title 			= {{ARM Expects Vehicle Compute Performance to Increase 100x in Next Decade}},
  note 				= {\url{https://www.arm.com/about/newsroom/arm-expects-vehicle-compute-performance-to-increase-100x-in-next-decade.php}},
  year 				= {2015},
}


@MANUAL{ESA-GR740,
  author = {{European Space Agency}},
  title = {{GR740: The ESA Next Generation Microprocessor (NGMP)}},
	note = {\url{http://microelectronics.esa.int/gr740/index.html}},
}

@MANUAL{LEON4N2X,
  author = {Cobham Gaisler},
  title = {GR-CPCI-LEON4-N2X Quad-Core LEON4 Next Generation Microprocessor Evaluation Board},
	note = {\url{http://www.gaisler.com/index.php/products/boards/gr-cpci-leon4-n2x}},
}


@article{WCETsurvey,
        author={Reinhard Wilhelm. et al},
        title={The worst-case execution time problem: overview of methods 
        and survey of tools},
        journal={ACM TECS},
        year={2008},
        volume={7},
        number={3},
        pages={1-53},
}
%        journal={Trans. on Embedded Computing Systems},

@INPROCEEDINGS{AbellaSIES2015,
author={J. Abella and C. Hernandez and E. Quiñones and F. J. Cazorla and P. R. Conmy and M. Azkarate-askasua and J. Perez and E. Mezzetti and T. Vardanega},
booktitle={10th IEEE International Symposium on Industrial Embedded Systems (SIES)},
title={WCET analysis methods: Pitfalls and challenges on their trustworthiness},
year={2015},
volume={},
number={},
pages={1-10},
doi={10.1109/SIES.2015.7185039},
ISSN={2150-3109},
month={June},}

@inproceedings{mbta_rolls_royce,
 author    = {S. Law and I. Bate},
 title     = {Achieving Appropriate Test Coverage for Reliable Measurement-Based Timing Analysis},
 booktitle = {{ECRTS}},
 year      = {2016},
}

@inproceedings{SIES-casestudy,
 author = {F. {Wartel et al.}},
 title = {Measurement-Based Probabilistic Timing Analysis: Lessons from an Integrated-Modular Avionics Case Study},
 booktitle = {SIES},
 year = {2013}
}

@inproceedings{DATE-casestudy,
 author = {F. {Wartel et al.}},
 title = {Timing Analysis of an Avionics Case Study on Complex Hardware/Software Platforms},
 booktitle = {DATE},
 year = {2015}
}

@inproceedings{space-casestudy,
 author = {M. {Fernandez et al.}},
 title = {Probabilistic Timing Analysis on Time-randomized Platforms for the Space Domain},
 booktitle = {DATE},
 year = {2017}
}

@inproceedings{INDINMBPTA,
  author    = {Z. {Stephenson et al.}},
  title     = {Supporting Industrial Use of Probabilistic Timing Analysis with Explicit Argumentation},
  booktitle = {INDIN},
  year = {2013},
}

@inproceedings{TASA,
 author = {L. {Kosmidis et al.}},
 title = {{TASA}: {T}oolchain-agnostic {S}tatic {S}oftware {R}andomisation for
	 {C}ritical {R}eal-time {S}ystems},
 booktitle = {ICCAD},
 year = {2016},
} 

@Misc{RandHWLeon3,
howpublished = {\url{http://www.gaisler.com/index.php/products/processors/leon3}},
title = {{LEON3 Processor (Probabilistic platform)}},
author={{Cobham Gaisler}}
}


@inproceedings{KosDATE2013b,
  author    = {L. {Kosmidis et al.}},
  title     = {Probabilistic Timing Analysis on Conventional Cache Designs},
  booktitle = {DATE},
  year      = {2013},
}

@MISC{SoCLib,
    author = {SoCLib},
    title  = {-},
    note   = {http://www.soclib.fr/trac/dev},
    year = {2003-2012},
 }

